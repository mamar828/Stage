{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import graphinglib as gl\n",
    "import gzip\n",
    "import dill\n",
    "import pyregion\n",
    "\n",
    "from src.tools.statistics.advanced_stats import increments\n",
    "from src.hdu.maps.map import Map\n",
    "from src.hdu.maps.convenient_funcs import get_speed\n",
    "from src.hdu.cubes.cube import Cube\n",
    "from src.tools.zurflueh_filter.zfilter import zfilter\n",
    "from src.tools.messaging import telegram_send_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plottables(data: np.ndarray, number_of_bins: int=None, increment: float=None) -> list:\n",
    "    sorted_data = np.sort(np.concatenate((data, -data)))\n",
    "\n",
    "    bin_width = 0.5\n",
    "    # bin_width = 125\n",
    "    bins = np.arange(np.nanmin(sorted_data), np.nanmax(sorted_data) + bin_width*0.99, bin_width)\n",
    "    max_bin = np.nanmax(sorted_data + bin_width)//bin_width * bin_width\n",
    "    bins = np.arange(-max_bin, max_bin, bin_width)\n",
    "\n",
    "    hist = gl.Histogram(\n",
    "        sorted_data,\n",
    "        number_of_bins=bins,\n",
    "        # number_of_bins=number_of_bins,\n",
    "        show_params=False\n",
    "    )\n",
    "    amplitude = np.max(hist.bin_heights)\n",
    "\n",
    "    stddev = hist.bin_centers[np.argmin(np.abs(hist.bin_heights - np.max(hist.bin_heights)/2))] / (np.sqrt(2*np.log(2)))\n",
    "    # stddev = hist_edges[np.argmin(np.abs(hist.bin_heights - np.max(hist.bin_heights)/2)) + 1] / (np.sqrt(2*np.log(2)))\n",
    "    # Half the bin_width could be added so the gaussian passes in the middle of the bins\n",
    "\n",
    "    curve = gl.Curve.from_function(\n",
    "        func=lambda x: amplitude * np.exp(-x**2/(2*stddev**2)),\n",
    "        x_min=hist.bin_edges[0],\n",
    "        x_max=hist.bin_edges[-1],\n",
    "        color=\"black\"\n",
    "    )\n",
    "\n",
    "    text = gl.Text(\n",
    "        hist.bin_edges[0]*0.8,\n",
    "        np.max(hist.bin_heights)*0.8,\n",
    "        rf\"$\\Delta={increment}$\"\n",
    "    )\n",
    "\n",
    "    return [hist, curve]#, text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All turbulence increments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbulence = Map.load(\"summer_2023/gaussian_fitting/maps/computed_data_selective/turbulence.fits\")\n",
    "\n",
    "regions = [\n",
    "    (\"global_region\", None, 40),\n",
    "    (\"diffuse_region\", pyregion.open(\"summer_2023/gaussian_fitting/regions/region_1.reg\"), 30),\n",
    "    (\"central_region\", pyregion.open(\"summer_2023/gaussian_fitting/regions/region_2.reg\"), 20),\n",
    "    (\"filament_region\", pyregion.open(\"summer_2023/gaussian_fitting/regions/region_3.reg\"), 10)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_figs = []\n",
    "\n",
    "VAL = 0.5\n",
    "\n",
    "for name, region, number_of_bins in regions:\n",
    "    increments_data = increments(turbulence.get_masked_region(region).data)\n",
    "\n",
    "    figs = []\n",
    "\n",
    "    for increment in [2,5,10,20]:\n",
    "        fig = gl.Figure(x_label=\" \", y_label=\" \")#, title=name)\n",
    "        data = []\n",
    "        for increment_i, values in increments_data.items():\n",
    "            if increment + VAL > increment_i > increment - VAL:\n",
    "                data.extend(values.tolist())\n",
    "        hist, curve = get_plottables(np.array(data), number_of_bins, increment)\n",
    "        fig.add_elements(hist, curve)\n",
    "        fig.x_lim = hist.bin_edges[0]*0.99, - hist.bin_edges[0]*0.99\n",
    "        # fig.add_elements(*get_plottables(increments_data[increment], number_of_bins, increment))\n",
    "        figs.append(fig)\n",
    "        \n",
    "    all_figs.extend(figs)\n",
    "\n",
    "    # multifig = gl.MultiFigure.from_grid(figs, (2,2), (14, 9))\n",
    "    # multifig.show()\n",
    "    # multifig.save(f\"figures/sh158/advanced_stats/increments/{name}.pdf\")\n",
    "\n",
    "figs_array = np.array(all_figs).reshape((4,4))\n",
    "\n",
    "figs_array[0,0].title = r\"$\\Delta=2$\"\n",
    "figs_array[0,1].title = r\"$\\Delta=5$\"\n",
    "figs_array[0,2].title = r\"$\\Delta=10$\"\n",
    "figs_array[0,3].title = r\"$\\Delta=20$\"\n",
    "\n",
    "giga_multifig = gl.MultiFigure.from_grid(figs_array.flatten().tolist(), (4,4), (13.065,9))\n",
    "\n",
    "giga_multifig.x_label = \"Normalized Increment [-]\"\n",
    "giga_multifig.y_label = \"Normalized Count [-]\"\n",
    "giga_multifig.title = \" \"\n",
    "\n",
    "giga_multifig.save(f\"figures/sh158/advanced_stats/increments/increments_article_new_2.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All nii_mean filtered increments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_cube = Cube.load(\"summer_2023/gaussian_fitting/data_cubes/night_34_wcs.fits\")\n",
    "nii_mean = get_speed(Map.load(\"data/sh158/fit_no_bin/NII_mean.fits\"), ref_cube)\n",
    "nii_regions = [\n",
    "    (\"global_region\", pyregion.open(\"data/sh158/turb.reg\")),\n",
    "    (\"diffuse_region\", pyregion.open(\"summer_2023/gaussian_fitting/regions/region_1.reg\")),\n",
    "    (\"central_region\", pyregion.open(\"summer_2023/gaussian_fitting/regions/region_2.reg\")),\n",
    "    (\"filament_region\", pyregion.open(\"summer_2023/gaussian_fitting/regions/region_3.reg\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_figs = []\n",
    "\n",
    "VAL = 0.5\n",
    "\n",
    "zfilter_widths = [81, 65, 31, 33]\n",
    "fig_x_lims = [(-20, 20), (-15, 15), (-10, 10), (-6.5, 6.5)]\n",
    "for (name, region), zfilter_width, x_lim in zip(nii_regions, zfilter_widths, fig_x_lims):\n",
    "    masked_map = nii_mean.get_masked_region(region)\n",
    "    gradient = Map(zfilter(masked_map.data, zfilter_width), 0)\n",
    "    filtered_map = masked_map - gradient\n",
    "    # np.save(\"figures/sh158/nii_mean/increments.npy\", increments_data)\n",
    "    # raise\n",
    "    if name == \"global_region\":\n",
    "        increments_data = np.load(\"figures/sh158/nii_mean/increments.npy\")\n",
    "    else:\n",
    "        increments_data = increments(filtered_map.crop_nans().data)\n",
    "\n",
    "    figs = []\n",
    "\n",
    "    for increment in [2,5,10,20]:\n",
    "        fig = gl.Figure(x_label=\" \", y_label=\" \", x_lim=x_lim)#, title=name)\n",
    "        data = []\n",
    "        for increment_i, values in increments_data.items():\n",
    "            if increment + VAL > increment_i > increment - VAL:\n",
    "                data.extend(values.tolist())\n",
    "        hist, curve = get_plottables(np.array(data))\n",
    "        fig.add_elements(hist, curve)\n",
    "        # fig.x_lim = hist.bin_edges[0]*0.99, - hist.bin_edges[0]*0.99\n",
    "        # fig.add_elements(*get_plottables(increments_data[increment], number_of_bins, increment))\n",
    "        figs.append(fig)\n",
    "        \n",
    "    all_figs.extend(figs)\n",
    "\n",
    "    # multifig = gl.MultiFigure.from_grid(figs, (2,2), (14, 9))\n",
    "    # multifig.show()\n",
    "    # multifig.save(f\"figures/sh158/advanced_stats/increments/{name}.pdf\")\n",
    "\n",
    "figs_array = np.array(all_figs).reshape((4,4))\n",
    "\n",
    "figs_array[0,0].title = r\"$\\Delta=2$\"\n",
    "figs_array[0,1].title = r\"$\\Delta=5$\"\n",
    "figs_array[0,2].title = r\"$\\Delta=10$\"\n",
    "figs_array[0,3].title = r\"$\\Delta=20$\"\n",
    "\n",
    "giga_multifig = gl.MultiFigure.from_grid(figs_array.flatten().tolist(), (4,4), (13.065,9))\n",
    "\n",
    "giga_multifig.x_label = \"Normalized Increment [-]\"\n",
    "giga_multifig.y_label = \"Normalized Count [-]\"\n",
    "giga_multifig.title = \" \"\n",
    "\n",
    "giga_multifig.save(f\"figures/sh158/nii_mean/increments_2.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All nii_mean **UN**filtered increments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_figs = []\n",
    "\n",
    "VAL = 0.5\n",
    "\n",
    "fig_x_lims = [(-20, 20), (-15, 15), (-10, 10), (-6.5, 6.5)]\n",
    "for (name, region), x_lim in zip(nii_regions, fig_x_lims):\n",
    "    masked_map = nii_mean.get_masked_region(region)\n",
    "    increments_data = increments(masked_map.crop_nans().data)\n",
    "    telegram_send_message(\"Increments finished calculating.\")\n",
    "    with gzip.open(\"figures/sh158/nii_mean/increments_unfiltered.gz\", \"wb\") as f:\n",
    "        # Only save increments that will be used later\n",
    "        save_data = {}\n",
    "        for increment in [2,5,10,20]:\n",
    "            for increment_i, values in increments_data.items():\n",
    "                if increment + VAL > increment_i > increment - VAL:\n",
    "                    save_data.update(values)\n",
    "        dill.dump(save_data, f)\n",
    "    telegram_send_message(\"All finished.\")\n",
    "    raise\n",
    "\n",
    "    if name == \"global_region\":\n",
    "        with gzip.open(\"figures/sh158/nii_mean/increments_unfiltered.gz\", \"rb\") as f:\n",
    "            increments_data = dill.load(f)\n",
    "    else:\n",
    "        increments_data = increments(masked_map.crop_nans().data)\n",
    "\n",
    "    figs = []\n",
    "    for increment in [2,5,10,20]:\n",
    "        fig = gl.Figure(x_label=\" \", y_label=\" \", x_lim=x_lim)\n",
    "        data = []\n",
    "        for increment_i, values in increments_data.items():\n",
    "            if increment + VAL > increment_i > increment - VAL:\n",
    "                data.extend(values.tolist())\n",
    "        hist, curve = get_plottables(np.array(data))\n",
    "        fig.add_elements(hist, curve)\n",
    "        figs.append(fig)\n",
    "        \n",
    "    all_figs.extend(figs)\n",
    "\n",
    "figs_array = np.array(all_figs).reshape((4,4))\n",
    "\n",
    "figs_array[0,0].title = r\"$\\Delta=2$\"\n",
    "figs_array[0,1].title = r\"$\\Delta=5$\"\n",
    "figs_array[0,2].title = r\"$\\Delta=10$\"\n",
    "figs_array[0,3].title = r\"$\\Delta=20$\"\n",
    "\n",
    "giga_multifig = gl.MultiFigure.from_grid(figs_array.flatten().tolist(), (4,4), (13.065,9))\n",
    "\n",
    "# giga_multifig.x_label = \" \"\n",
    "# giga_multifig.y_label = \" \"\n",
    "# giga_multifig.title = \" \"\n",
    "\n",
    "giga_multifig.save(f\"figures/sh158/nii_mean/increments_unfiltered.pdf\", dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
