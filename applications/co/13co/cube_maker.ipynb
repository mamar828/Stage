{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import os\n",
    "import re\n",
    "from xattr import xattr\n",
    "\n",
    "from src.hdu.cubes.cube import Cube\n",
    "from src.hdu.arrays.array_3d import Array3D\n",
    "from src.headers.header import Header\n",
    "from src.coordinates.equatorial_coords import RA, DEC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following document helped to understang the Global Sinusoidal (GLS) projection : [Multi-Beam FITS Raw Data Format, page 15](https://fits.gsfc.nasa.gov/registry/mbfits/APEX-MPI-ICD-0002-R1_66.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_id(id: str) -> np.ndarray:\n",
    "    \"\"\" \n",
    "    Translates a string id into a vector.\n",
    "    \"\"\"\n",
    "    translation = {\n",
    "        \"N\" : np.array([ 0, 1]),\n",
    "        \"S\" : np.array([ 0,-1]),\n",
    "        \"E\" : np.array([-1, 0]),\n",
    "        \"W\" : np.array([ 1, 0])\n",
    "    }\n",
    "\n",
    "    # Define the pattern to match letter followed by digits\n",
    "    pattern = re.compile(r\"([A-Za-z])(\\d*)\")\n",
    "    matches = pattern.findall(id)\n",
    "    result = np.array([0, 0])\n",
    "    for letter, number in matches:\n",
    "        if letter.upper() not in list(translation.keys()):\n",
    "            continue\n",
    "        if number == \"\":\n",
    "            number = 1\n",
    "        else:\n",
    "            number = int(number)\n",
    "        result += translation[letter.upper()] * number\n",
    "    \n",
    "    return result\n",
    "\n",
    "def set_region(cube_data: np.ndarray, center: np.ndarray, region: fits.HDUList):\n",
    "    \"\"\"\n",
    "    Sets a region of a given cube.\n",
    "    \"\"\"\n",
    "    smart_slice = lambda start, length: slice(int(start), int(start+length))\n",
    "    cube_data[\n",
    "        :int(region.header[\"NAXIS3\"]),\n",
    "        smart_slice(center[1]-region.header[\"CRPIX2\"], region.header[\"NAXIS2\"]),\n",
    "        smart_slice(center[0]-region.header[\"CRPIX1\"], region.header[\"NAXIS1\"])\n",
    "    ] = region.data\n",
    "\n",
    "def get_cleaned_header(header: Header) -> Header:\n",
    "    \"\"\"\n",
    "    Filters the given header to remove any invalid keywords.\n",
    "    \"\"\"\n",
    "    valid_cards = []\n",
    "    valid_keywords = [\n",
    "        \"SIMPLE\", \"BITPIX\", \"NAXIS\", \"NAXIS1\", \"NAXIS2\", \"NAXIS3\", \"BUNIT\", \"EQUINOX\", \"CRPIX1\", \"CRPIX2\", \"CROTA1\",\n",
    "        \"CROTA2\", \"CRVAL1\", \"CRVAL2\", \"CTYPE1\", \"CTYPE2\", \"CDELT1\", \"CDELT2\", \"CRPIX3\", \"CROTA3\", \"CRVAL3\", \"CTYPE3\",\n",
    "        \"CDELT3\", \"BUNIT\", \"OBSERVER\", \"LINE\", \"EQUINOX\", \"VELO-LSR\"\n",
    "    ]\n",
    "    for card in header.cards:\n",
    "        if card.keyword in valid_keywords:\n",
    "            valid_cards.append(fits.Card(\n",
    "                keyword=card.keyword,\n",
    "                value=card.value,\n",
    "                comment=card.comment\n",
    "            ))\n",
    "    \n",
    "    return Header(valid_cards)\n",
    "\n",
    "def set_header(target_cube: Cube, reference_cube: Cube):\n",
    "    target_cube.header[\"CTYPE1\"] = reference_cube.header[\"CTYPE1\"]\n",
    "    target_cube.header[\"CTYPE2\"] = reference_cube.header[\"CTYPE2\"]\n",
    "    target_cube.header[\"CDELT1\"] = reference_cube.header[\"CDELT1\"]\n",
    "    target_cube.header[\"CDELT2\"] = reference_cube.header[\"CDELT2\"]\n",
    "    target_cube.header[\"CRPIX1\"] = reference_cube.header[\"CRPIX1\"]\n",
    "    target_cube.header[\"CRPIX2\"] = reference_cube.header[\"CRPIX2\"]\n",
    "    target_cube.header[\"CRVAL1\"] = reference_cube.header[\"CRVAL1\"]\n",
    "    target_cube.header[\"CRVAL2\"] = reference_cube.header[\"CRVAL2\"]\n",
    "    return target_cube\n",
    "\n",
    "def build_cube(prefix: str, ref_cube: Cube) -> Cube:\n",
    "    # Create an empty Cube of arbitrary size\n",
    "    cube_data = np.full((10000, 200, 200), np.NAN)\n",
    "    files = os.listdir(f\"data/Loop4_co/13co_spectrums/{prefix}\")\n",
    "\n",
    "    # Create an arbitrary center\n",
    "    center = np.array([100, 100])\n",
    "\n",
    "    # Iterate over the files in the directory to get only the cubes\n",
    "    # Individual spectrums are added afterwards as the addition of a spectrum, then a cube at the same position\n",
    "    # overwrites the previous spectrum\n",
    "    first_file = True\n",
    "    for file in filter(lambda f: not f.endswith(\"-s.fits\"), files):\n",
    "        if file == \"N4S4.fits\": continue        # Do not include this file as it has an inconsistent spectral resolution\n",
    "        subregion = fits.open(f\"data/Loop4_co/13co_spectrums/{prefix}/{file}\")[0]\n",
    "        subregion_id = file[len(prefix):-5]\n",
    "        if first_file:\n",
    "            cube_header = fits.open(f\"data/Loop4_co/13co_spectrums/{prefix}/{file}\")[0].header\n",
    "            CRPIX_offset = - 2 + translate_id(subregion_id)*3\n",
    "            cube_header[\"CRPIX1\"] += center[0] + CRPIX_offset[0]\n",
    "            cube_header[\"CRPIX2\"] += center[1] + CRPIX_offset[1]\n",
    "            first_file = False\n",
    "        set_region(cube_data, center + translate_id(subregion_id)*3, subregion)\n",
    "\n",
    "    # Loop on all the spectrum files, if any\n",
    "    for file in filter(lambda f: f.endswith(\"-s.fits\"), files):\n",
    "        # Filter out grey tags (only relevant for Loop4p spectrums)\n",
    "        try:\n",
    "            if (xattr(f\"data/Loop4_co/13co_spectrums/{prefix}/{file}\")['com.apple.FinderInfo'][9] >> 1 & 7) == 1:\n",
    "                # Files with the grey tag on top will be skipped\n",
    "                continue\n",
    "        except KeyError:\n",
    "            # The file does not have any tag ->Â will be considered by default\n",
    "            pass\n",
    "\n",
    "        subregion = fits.open(f\"data/Loop4_co/13co_spectrums/{prefix}/{file}\")[0]\n",
    "        subregion_id = file[len(prefix):-5]\n",
    "        subregion_center = center + translate_id(subregion_id[:-2])*3\n",
    "        cube_data[\n",
    "            :int(subregion.header[\"NAXIS1\"]),\n",
    "            subregion_center[1]-1,\n",
    "            subregion_center[0]-1\n",
    "        ] = subregion.data\n",
    "\n",
    "    cube_data[cube_data == 0] = np.NAN\n",
    "    cube = Cube(Array3D(cube_data), get_cleaned_header(cube_header))\n",
    "    cube.header[\"OBJECT\"] = f\"Loop4{prefix}\"\n",
    "\n",
    "    # Crop the cube to the same dimensions\n",
    "    x_lower_limit = round(cube.header[\"CRPIX1\"] - ref_cube.header.get_coordinate(cube.header[\"CRVAL1\"], 2))\n",
    "    y_lower_limit = round(cube.header[\"CRPIX2\"] - ref_cube.header.get_coordinate(cube.header[\"CRVAL2\"], 1))\n",
    "    x_upper_limit = round(x_lower_limit + ref_cube.header[\"NAXIS1\"])\n",
    "    y_upper_limit = round(y_lower_limit + ref_cube.header[\"NAXIS2\"])\n",
    "    z_upper_limit = round(np.where(np.all(np.isnan(cube.data), axis=(1,2)))[0][0])\n",
    "\n",
    "    cube = cube[:z_upper_limit, y_lower_limit:y_upper_limit, x_lower_limit:x_upper_limit]\n",
    "\n",
    "    # The last step is to perfectly align the header using the 12CO aligned cube (also change the projection CAR)\n",
    "    set_header(cube, ref_cube)\n",
    "    cube.save(f\"data/Loop4_co/{prefix}/13co/Loop4{prefix}_13co.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_cube(\"N1\", ref_cube=Cube.load(\"data/Loop4_co/N1/12co/Loop4N1_wcs.fits\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_cube(\"N2\", ref_cube=Cube.load(\"data/Loop4_co/N2/12co/Loop4N2_wcs.fits\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_cube(\"N4\", ref_cube=Cube.load(\"data/Loop4_co/N4/12co/Loop4N4_wcs.fits\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N4S4\n",
    "N4S4 = Cube.load(\"data/Loop4_co/13co_spectrums/N4/N4S4.fits\")\n",
    "N4S4.header = get_cleaned_header(N4S4.header)\n",
    "N4S4.save(\"data/Loop4_co/N4/13co/N4S4.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_cube(\"p\", ref_cube=Cube.load(\"data/Loop4_co/p/12co/Loop4p_wcs.fits\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RA(1.2683333439634e+02))\n",
    "print(DEC(6.0125000961653e+01))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
