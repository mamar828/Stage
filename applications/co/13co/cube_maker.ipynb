{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import os\n",
    "import re\n",
    "from xattr import xattr\n",
    "import scipy\n",
    "\n",
    "from src.hdu.cubes.cube import Cube\n",
    "from src.hdu.arrays.array_3d import Array3D\n",
    "from src.headers.header import Header\n",
    "from src.coordinates.equatorial_coords import RA, DEC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following document helped to understang the Global Sinusoidal (GLS) projection : [Multi-Beam FITS Raw Data Format, page 15](https://fits.gsfc.nasa.gov/registry/mbfits/APEX-MPI-ICD-0002-R1_66.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_id(id: str) -> np.ndarray:\n",
    "    \"\"\" \n",
    "    Translates a string id into a vector.\n",
    "    \"\"\"\n",
    "    translation = {\n",
    "        \"N\" : np.array([ 0, 1]),\n",
    "        \"S\" : np.array([ 0,-1]),\n",
    "        \"E\" : np.array([-1, 0]),\n",
    "        \"W\" : np.array([ 1, 0])\n",
    "    }\n",
    "\n",
    "    # Define the pattern to match letter followed by digits\n",
    "    pattern = re.compile(r\"([A-Za-z])(\\d*)\")\n",
    "    matches = pattern.findall(id)\n",
    "    result = np.array([0, 0])\n",
    "    for letter, number in matches:\n",
    "        if letter.upper() not in list(translation.keys()):\n",
    "            continue\n",
    "        if number == \"\":\n",
    "            number = 1\n",
    "        else:\n",
    "            number = int(number)\n",
    "        result += translation[letter.upper()] * number\n",
    "    \n",
    "    return result\n",
    "\n",
    "def set_region(cube_data: np.ndarray, center: np.ndarray, region: fits.HDUList):\n",
    "    \"\"\"\n",
    "    Sets a region of a given cube.\n",
    "    \"\"\"\n",
    "    smart_slice = lambda start, length: slice(int(start), int(start+length))\n",
    "    cube_data[\n",
    "        :int(region.header[\"NAXIS3\"]),\n",
    "        smart_slice(center[1]-region.header[\"CRPIX2\"], region.header[\"NAXIS2\"]),\n",
    "        smart_slice(center[0]-region.header[\"CRPIX1\"], region.header[\"NAXIS1\"])\n",
    "    ] = region.data\n",
    "\n",
    "def get_cleaned_header(header: Header) -> Header:\n",
    "    \"\"\"\n",
    "    Filters the given header to remove any invalid keywords.\n",
    "    \"\"\"\n",
    "    valid_cards = []\n",
    "    valid_keywords = [\n",
    "        \"SIMPLE\", \"BITPIX\", \"NAXIS\", \"NAXIS1\", \"NAXIS2\", \"NAXIS3\", \"BUNIT\", \"EQUINOX\", \"CRPIX1\", \"CRPIX2\", \"CROTA1\",\n",
    "        \"CROTA2\", \"CRVAL1\", \"CRVAL2\", \"CTYPE1\", \"CTYPE2\", \"CDELT1\", \"CDELT2\", \"CRPIX3\", \"CROTA3\", \"CRVAL3\", \"CTYPE3\",\n",
    "        \"CDELT3\", \"BUNIT\", \"OBSERVER\", \"LINE\", \"EQUINOX\", \"VELO-LSR\"\n",
    "    ]\n",
    "    for card in header.cards:\n",
    "        if card.keyword in valid_keywords:\n",
    "            valid_cards.append(fits.Card(\n",
    "                keyword=card.keyword,\n",
    "                value=card.value,\n",
    "                comment=card.comment\n",
    "            ))\n",
    "    \n",
    "    return Header(valid_cards)\n",
    "\n",
    "def set_header(target_cube: Cube, reference_cube: Cube):\n",
    "    target_cube.header[\"CTYPE1\"] = reference_cube.header[\"CTYPE1\"]\n",
    "    target_cube.header[\"CTYPE2\"] = reference_cube.header[\"CTYPE2\"]\n",
    "    target_cube.header[\"CDELT1\"] = reference_cube.header[\"CDELT1\"]\n",
    "    target_cube.header[\"CDELT2\"] = reference_cube.header[\"CDELT2\"]\n",
    "    target_cube.header[\"CRPIX1\"] = reference_cube.header[\"CRPIX1\"]\n",
    "    target_cube.header[\"CRPIX2\"] = reference_cube.header[\"CRPIX2\"]\n",
    "    target_cube.header[\"CRVAL1\"] = reference_cube.header[\"CRVAL1\"]\n",
    "    target_cube.header[\"CRVAL2\"] = reference_cube.header[\"CRVAL2\"]\n",
    "    return target_cube\n",
    "\n",
    "def smooth_40_arcsec(cube_data: np.ndarray, center: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Smooths the resolution of a Cube that was created using 40\" spacing.\n",
    "    \"\"\"\n",
    "    # start = center[0] % 3, center[1] % 3\n",
    "    s_s = lambda val: slice(val, val+2)\n",
    "    def get_mean_axes(y_offset: int, x_offset: int) -> int | tuple[int, int]:\n",
    "        if y_offset == 0 and x_offset != 0: return 2\n",
    "        elif y_offset != 0 and x_offset == 0: return 1\n",
    "        elif y_offset != 0 and x_offset != 0: return (1,2)\n",
    "        else: raise ValueError\n",
    "\n",
    "    new_data = cube_data.copy()\n",
    "    for y in range(cube_data.shape[1]):\n",
    "        y_offset = (y - center[0] + 1) % 3\n",
    "        for x in range(cube_data.shape[2]):\n",
    "            if not np.all(np.isnan(cube_data[:,y,x])):\n",
    "                x_offset = (x - center[1] + 1) % 3\n",
    "\n",
    "                # Offset table\n",
    "                # ------------\n",
    "                # 0: pixel is kept as is\n",
    "                # 1: pixel and its higher neighbor are averaged\n",
    "                # 2: pixel and its lower neighbor are averaged\n",
    "\n",
    "                if x_offset == 0 and y_offset == 0: continue        # no averaging needed\n",
    "\n",
    "                new_data[:,y,x] = np.nanmean(cube_data[\n",
    "                    :,\n",
    "                    s_s(y+1-y_offset) if y_offset != 0 else y,\n",
    "                    s_s(x+1-x_offset) if x_offset != 0 else x\n",
    "                ], axis=(1,2) if y_offset != 0 and x_offset != 0 else 1)\n",
    "\n",
    "    return new_data\n",
    "\n",
    "def build_cube(prefix: str, ref_cube: Cube, target_resolution: int=30) -> Cube:\n",
    "    # Create an empty Cube of arbitrary size\n",
    "    cube_data = np.full((10000, 200, 200), np.NAN)\n",
    "    files = os.listdir(f\"data/Loop4/13co_spectrums/{prefix}\")\n",
    "\n",
    "    # Create an arbitrary center\n",
    "    center = np.array([100, 100])\n",
    "\n",
    "    # Iterate over the files in the directory to get only the cubes\n",
    "    # Individual spectrums are added afterwards as the addition of a spectrum, then a cube at the same position\n",
    "    # overwrites the previous spectrum\n",
    "    first_file = True\n",
    "    for file in filter(lambda f: not f.endswith(\"-s.fits\"), files):\n",
    "        if file == \"N4S4.fits\": continue        # Do not include this file as it has an inconsistent spectral resolution\n",
    "        subregion = fits.open(f\"data/Loop4/13co_spectrums/{prefix}/{file}\")[0]\n",
    "        # Only study the targeted spatial resolution\n",
    "        if {30 : -8.3330000413708e-03, 40 : -1.1111000227158e-02}[target_resolution] == subregion.header[\"CDELT1\"]:\n",
    "            subregion_id = file[len(prefix):-5]\n",
    "            if first_file:\n",
    "                cube_header = fits.open(f\"data/Loop4/13co_spectrums/{prefix}/{file}\")[0].header\n",
    "                CRPIX_offset = - 2 + translate_id(subregion_id)*3\n",
    "                cube_header[\"CRPIX1\"] += center[0] + CRPIX_offset[0]\n",
    "                cube_header[\"CRPIX2\"] += center[1] + CRPIX_offset[1]\n",
    "                first_file = False\n",
    "            set_region(cube_data, center + translate_id(subregion_id)*3, subregion)\n",
    "\n",
    "    # Loop on all the spectrum files, if any\n",
    "    for file in filter(lambda f: f.endswith(\"-s.fits\"), files):\n",
    "        # Filter out grey tags (only relevant for Loop4p spectrums)\n",
    "        try:\n",
    "            if (xattr(f\"data/Loop4/13co_spectrums/{prefix}/{file}\")['com.apple.FinderInfo'][9] >> 1 & 7) == 1:\n",
    "                # Files with the grey tag on top will be skipped\n",
    "                continue\n",
    "        except KeyError:\n",
    "            # The file does not have any tag ->Â will be considered by default\n",
    "            pass\n",
    "\n",
    "        subregion = fits.open(f\"data/Loop4/13co_spectrums/{prefix}/{file}\")[0]\n",
    "        subregion_id = file[len(prefix):-5]\n",
    "        subregion_center = center + translate_id(subregion_id[:-2])*3\n",
    "        cube_data[\n",
    "            :int(subregion.header[\"NAXIS1\"]),\n",
    "            subregion_center[1]-1,\n",
    "            subregion_center[0]-1\n",
    "        ] = subregion.data\n",
    "\n",
    "    cube_data[cube_data == 0] = np.NAN\n",
    "    cube = Cube(Array3D(cube_data), get_cleaned_header(cube_header))\n",
    "    cube.header[\"OBJECT\"] = f\"Loop4{prefix}\"\n",
    "    cube.header[\"CTYPE3\"] = \"VELO-LSR\"\n",
    "    cube.header[\"CDELT3\"] = (- cube.header[\"CDELT3\"] / cube.header[\"CRVAL3\"] * scipy.constants.c,\n",
    "                             \"minus is attributed for consistency with 12CO\")\n",
    "    cube.header[\"CRVAL3\"] = cube.header[\"VELO-LSR\"]\n",
    "\n",
    "    if target_resolution == 40:\n",
    "        cube.data = smooth_40_arcsec(cube.data, center)\n",
    "\n",
    "    # Crop the cube to the same dimensions\n",
    "    x_lower_limit = round(cube.header[\"CRPIX1\"] - ref_cube.header.get_coordinate(cube.header[\"CRVAL1\"], 2))\n",
    "    y_lower_limit = round(cube.header[\"CRPIX2\"] - ref_cube.header.get_coordinate(cube.header[\"CRVAL2\"], 1))\n",
    "    if target_resolution == 40 and prefix == \"N4\":\n",
    "        x_lower_limit += 15\n",
    "    x_upper_limit = round(x_lower_limit + ref_cube.header[\"NAXIS1\"])\n",
    "    y_upper_limit = round(y_lower_limit + ref_cube.header[\"NAXIS2\"])\n",
    "    z_upper_limit = round(np.where(np.all(np.isnan(cube.data), axis=(1,2)))[0][0])\n",
    "\n",
    "    cube = cube[:z_upper_limit, y_lower_limit:y_upper_limit, x_lower_limit:x_upper_limit]\n",
    "\n",
    "    # The last step is to perfectly align the header using the 12CO aligned cube (also change the projection CAR)\n",
    "    set_header(cube, ref_cube)\n",
    "    if prefix == \"N4\":\n",
    "        return cube\n",
    "    else:\n",
    "        cube.save(f\"data/Loop4/{prefix}/13co/Loop4{prefix}_13co.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_cube(\"N1\", ref_cube=Cube.load(\"data/Loop4/N1/12co/Loop4N1_wcs.fits\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_cube(\"N2\", ref_cube=Cube.load(\"data/Loop4/N2/12co/Loop4N2_wcs.fits\"), target_resolution=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N4_30 = build_cube(\"N4\", ref_cube=Cube.load(\"data/Loop4/N4/12co/Loop4N4_wcs.fits\"), target_resolution=30)\n",
    "N4_40 = build_cube(\"N4\", ref_cube=Cube.load(\"data/Loop4/N4/12co/Loop4N4_wcs.fits\"), target_resolution=40)\n",
    "\n",
    "data = np.nan_to_num(N4_30.data) + np.nan_to_num(N4_40.data)\n",
    "data[:,np.all(data == 0, axis=0)] = np.NAN\n",
    "\n",
    "cube = Cube(data, N4_30.header)\n",
    "cube.save(\"data/Loop4/N4/13co/Loop4N4_13co.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N4S4\n",
    "N4S4 = Cube.load(\"data/Loop4/13co_spectrums/N4/N4S4.fits\")\n",
    "N4S4.header = get_cleaned_header(N4S4.header)\n",
    "N4S4.save(\"data/Loop4/N4/13co/N4S4.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_cube(\"p\", ref_cube=Cube.load(\"data/Loop4/p/12co/Loop4p_wcs.fits\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RA(1.2204916937333e+02))\n",
    "print(DEC(6.1245828174262e+01))\n",
    "print(RA(121.99833910553 - 121.79500437394))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying the CDELT1 and CDELT2 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_CDELTS(prefix: str):\n",
    "    print(prefix)\n",
    "    for file in os.listdir(f\"data/Loop4/13co_spectrums/{prefix}\"):\n",
    "        cube = Cube.load(f\"data/Loop4/13co_spectrums/{prefix}/{file}\")\n",
    "        print(f\"\\t{file[:-5]+\" :\":8}\\t{cube.header[\"CDELT1\"]} x {cube.header[\"CDELT2\"]} x {cube.header[\"CDELT3\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_CDELTS(\"N1\")\n",
    "list_CDELTS(\"N2\")\n",
    "list_CDELTS(\"N4\")\n",
    "list_CDELTS(\"p\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
