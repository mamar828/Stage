{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kinetic temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kinetic temperature is obtained with the 12CO amplitude :\n",
    "$$T_{kin}=T_{x}=\\frac{5.532}{\\ln\\left(1+\\left(\\frac{T_A}{5.532}+0.151\\right)^{-1}\\right)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hdu.maps.map import Map\n",
    "from src.hdu.cubes.cube_co import CubeCO\n",
    "from src.hdu.tesseract import Tesseract\n",
    "from src.hdu.maps.grouped_maps import GroupedMaps\n",
    "from src.hdu.maps.convenient_funcs import get_kinetic_temperature\n",
    "from src.coordinates.ds9_coords import DS9Coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kinetic_temperature(prefix: str):\n",
    "    GroupedMaps([(\n",
    "        \"kinetic_temperature\", [\n",
    "            get_kinetic_temperature(amp) for amp in Tesseract.load(\n",
    "                f\"data/Loop4/{prefix}/12co/object_filtered.fits\"\n",
    "            ).to_grouped_maps().amplitude\n",
    "        ]\n",
    "    )])#.save(f\"data/Loop4/{prefix}/12co/kinetic_temperature.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_kinetic_temperature(\"N1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_kinetic_temperature(\"N2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_kinetic_temperature(\"N4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_kinetic_temperature(\"p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column density is obtained using the following equation (Interstellar And Intergalactic Medium, Barbara Ryden and Richard W. Pogge):\n",
    "\\begin{align*}\n",
    "    N_0\\left(^{13}\\text{CO}\\right)=\\int_{-\\infty}^\\infty T_A\\left(^{13}\\text{CO}\\right)dv\\cdot0.8\\cdot\\frac{g_0}{g_1A_{10}}\\cdot\\frac{\\pi k\\nu^2}{hc^3}\\left[\\left(\\frac1{\\exp\\left(\\frac{h\\nu}{kT_x}\\right)-1}-\\frac1{\\exp\\left(\\frac{h\\nu}{kT_{rad}}\\right)-1}\\right)\\left(1-\\exp\\left(-\\frac{h\\nu}{kT_x}\\right)\\right)\\right]^{-1}\n",
    "\\end{align*}\n",
    "knowing that\n",
    "\\begin{align*}\n",
    "    \\int_{-\\infty}^\\infty T_A\\left(^{13}\\text{CO}\\right)dv&=2T_A\\sigma\\sqrt{\\frac\\pi2}\\text{erf}\\left(\\frac{\\infty}{\\sqrt2\\sigma}\\right)\\\\\n",
    "    &=2T_A\\sigma\\sqrt{\\frac\\pi2}\\\\\n",
    "\\end{align*}\n",
    "as\n",
    "$$\\lim_{x\\rightarrow\\infty}\\text{erf}(x)=1$$\n",
    "we obtain\n",
    "$$N_0\\left(^{13}\\text{CO}\\right)=2T_A\\sigma\\sqrt{\\frac\\pi2}\\cdot0.8\\cdot\\frac{g_0}{g_1A_{10}}\\cdot\\frac{\\pi k\\nu^2}{hc^3}\\left[\\left(\\frac1{\\exp\\left(\\frac{h\\nu}{kT_x}\\right)-1}-\\frac1{\\exp\\left(\\frac{h\\nu}{kT_{rad}}\\right)-1}\\right)\\left(1-\\exp\\left(-\\frac{h\\nu}{kT_x}\\right)\\right)\\right]^{-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import src.graphinglib as gl\n",
    "import importlib\n",
    "import scipy\n",
    "from typing import Literal\n",
    "from astropy.constants import M_sun\n",
    "\n",
    "import src.hdu.maps.convenient_funcs\n",
    "importlib.reload(src.hdu.maps.convenient_funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_single_component_column_density_and_13co_opacity(prefix: Literal[\"N1\", \"N2\", \"N4\", \"p\"]):\n",
    "    cube_12co = CubeCO.load(f\"data/Loop4/{prefix}/12co/Loop4{prefix}_wcs.fits\")\n",
    "    cube_13co = CubeCO.load(f\"data/Loop4/{prefix}/13co/Loop4{prefix}_13co.fits\")\n",
    "    maps_12co = Tesseract.load(f\"data/Loop4/{prefix}/12co/object_filtered.fits\").to_grouped_maps()\n",
    "    maps_13co = Tesseract.load(f\"data/Loop4/{prefix}/13co/tesseract.fits\").to_grouped_maps()\n",
    "\n",
    "    # The right gaussians first need to be selected\n",
    "    # This solution is for single component 13co maps\n",
    "    assert len(maps_13co.mean) == 1\n",
    "    mean_12co = np.stack([m.get_reprojection_on(maps_13co.mean[0].header).data for m in maps_12co.mean], axis=0)\n",
    "    offset_12 = sum([int(line.split(\" \")[5][:-1]) if line[12:33] == \"was sliced at channel\" else 0\n",
    "                     for line in maps_12co.mean[0].header[\"COMMENT\"]])\n",
    "    offset_13 = sum([int(line.split(\" \")[5][:-1]) if line[13:34] == \"was sliced at channel\" else 0\n",
    "                     for line in maps_13co.mean[0].header[\"COMMENT\"]])\n",
    "\n",
    "    speed_convert_12 = np.vectorize(cube_12co.header.get_value)\n",
    "    speed_convert_13 = np.vectorize(cube_13co.header.get_value)\n",
    "    # Compute the diff between the centroid of every gaussian\n",
    "    diff_array = np.abs(speed_convert_12(mean_12co + offset_12)\n",
    "                      - speed_convert_13(maps_13co.mean[0].data + offset_13))\n",
    "    nan_mask = np.isnan(diff_array)     # Apply a nan mask to allow proper argmin use\n",
    "    diff_array[nan_mask] = 2**15-1      # Remove nans\n",
    "    min_mask = np.argmin(diff_array, axis=0)\n",
    "    filter_gaussians = lambda arr: np.take_along_axis(arr, min_mask[np.newaxis, ...], axis=0).squeeze()\n",
    "\n",
    "    amp_12co_val = np.stack(\n",
    "        [m.get_reprojection_on(maps_13co.mean[0].header).data for m in maps_12co.amplitude], axis=0\n",
    "    )\n",
    "    amp_12co_unc = np.stack(\n",
    "        [m.get_reprojection_on(maps_13co.mean[0].header).uncertainties for m in maps_12co.amplitude], axis=0\n",
    "    )\n",
    "\n",
    "    amplitude_correction_factor_13co = 0.43\n",
    "    src.hdu.maps.convenient_funcs.get_13co_column_density(\n",
    "        stddev_13co=maps_13co.stddev[0]*np.abs(cube_13co.header[\"CDELT3\"]/1000),\n",
    "        antenna_temperature_13co=maps_13co.amplitude[0]/amplitude_correction_factor_13co,\n",
    "        antenna_temperature_12co=Map(filter_gaussians(amp_12co_val), filter_gaussians(amp_12co_unc))\n",
    "    ).save(f\"data/Loop4/{prefix}/13co/{prefix}_column_density.fits\")\n",
    "    src.hdu.maps.convenient_funcs.get_13co_opacity(\n",
    "        stddev_13co=maps_13co.stddev[0]*np.abs(cube_13co.header[\"CDELT3\"]/1000),\n",
    "        antenna_temperature_13co=maps_13co.amplitude[0]/amplitude_correction_factor_13co,\n",
    "        antenna_temperature_12co=Map(filter_gaussians(amp_12co_val), filter_gaussians(amp_12co_unc))\n",
    "    ).save(f\"data/Loop4/{prefix}/13co/{prefix}_opacity.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_single_component_column_density_and_13co_opacity(\"N1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_single_component_column_density_and_13co_opacity(\"N2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_single_component_column_density_and_13co_opacity(\"N4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop4p multiple components\n",
    "import scipy.optimize\n",
    "\n",
    "cube_12co = CubeCO.load(\"data/Loop4/p/12co/Loop4p_wcs.fits\")\n",
    "cube_13co = CubeCO.load(\"data/Loop4/p/13co/Loop4p_13co.fits\")\n",
    "maps_12co = Tesseract.load(\"data/Loop4/p/12co/object_filtered.fits\").to_grouped_maps()\n",
    "maps_13co = Tesseract.load(\"data/Loop4/p/13co/object_filtered.fits\").to_grouped_maps()\n",
    "\n",
    "mean_12co = np.stack([m.get_reprojection_on(maps_13co.mean[0].header).data for m in maps_12co.mean], axis=0)\n",
    "mean_13co = np.stack([m.data for m in maps_13co.mean], axis=0)\n",
    "ampl_12co_val = np.stack([m.get_reprojection_on(maps_13co.amplitude[0].header).data\n",
    "                          for m in maps_12co.amplitude], axis=0)\n",
    "ampl_12co_unc = np.stack([m.get_reprojection_on(maps_13co.amplitude[0].header).uncertainties\n",
    "                          for m in maps_12co.amplitude], axis=0)\n",
    "\n",
    "ordered_stddev_13co = np.full([*mean_13co.shape, 2], np.NAN)\n",
    "ordered_amplitude_13co = np.full([*mean_13co.shape, 2], np.NAN)\n",
    "ordered_amplitude_12co = np.full([*mean_13co.shape, 2], np.NAN)\n",
    "\n",
    "speed_convert_12 = np.vectorize(cube_12co.header.get_value)\n",
    "speed_convert_13 = np.vectorize(cube_13co.header.get_value)\n",
    "\n",
    "def minimize(target: np.ndarray, ref: np.ndarray):\n",
    "    \"\"\"\n",
    "    Minimizes the distance between two groups of points and gives the matching indices.\n",
    "    \"\"\"\n",
    "    # Create a cost matrix where the element at position (i, j) represents the difference between list1[i] and list2[j]\n",
    "    cost_matrix = np.abs(np.subtract.outer(target[~np.isnan(target)], ref[~np.isnan(ref)]))\n",
    "    # Use linear_sum_assignment to find the optimal assignment\n",
    "    row_indices, col_indices = scipy.optimize.linear_sum_assignment(cost_matrix)\n",
    "    # Create a list of tuples representing the pairs\n",
    "    pairs = list(zip(row_indices, col_indices))\n",
    "    # Check if the pairs are close enough, otherwise the pair is considered invalid\n",
    "    velocity_upper_limit = 100\n",
    "    valid_pairs = []\n",
    "    for pair in pairs:\n",
    "        if np.abs(target[pair[0]] - ref[pair[1]]) < velocity_upper_limit:\n",
    "            valid_pairs.append(pair)\n",
    "    return valid_pairs\n",
    "\n",
    "for y in range(mean_13co.shape[1]):\n",
    "    for x in range(mean_13co.shape[2]):\n",
    "        if not np.isnan(mean_13co[0,y,x]):\n",
    "            matches = minimize(speed_convert_13(mean_13co[:,y,x]+400), speed_convert_12(mean_12co[:,y,x]+500))\n",
    "            for match in matches:\n",
    "                ordered_stddev_13co[match[0],y,x] = [\n",
    "                    maps_13co.stddev[match[0]].data[y,x],\n",
    "                    maps_13co.stddev[match[0]].uncertainties[y,x]\n",
    "                ]\n",
    "                ordered_amplitude_13co[match[0],y,x] = [\n",
    "                    maps_13co.amplitude[match[0]].data[y,x],\n",
    "                    maps_13co.amplitude[match[0]].uncertainties[y,x]\n",
    "                ]\n",
    "                ordered_amplitude_12co[match[0],y,x] = [\n",
    "                    ampl_12co_val[match[1],y,x],\n",
    "                    ampl_12co_unc[match[1],y,x]\n",
    "                ]\n",
    "\n",
    "amplitude_correction_factor_13co = 0.43\n",
    "column_densities = []\n",
    "opacities = []\n",
    "for i in range(mean_13co.shape[0]):\n",
    "    stddev_13co = Map(\n",
    "        data=ordered_stddev_13co[i,:,:,0],\n",
    "        uncertainties=ordered_stddev_13co[i,:,:,1],\n",
    "        header=maps_13co.mean[0].header,\n",
    "    ) * np.abs(cube_13co.header[\"CDELT3\"]/1000)\n",
    "    antenna_temperature_13co = Map(\n",
    "        data=ordered_amplitude_13co[i,:,:,0],\n",
    "        uncertainties=ordered_amplitude_13co[i,:,:,1],\n",
    "        header=maps_13co.mean[0].header,\n",
    "    ) / amplitude_correction_factor_13co\n",
    "    antenna_temperature_12co = Map(\n",
    "        data=ordered_amplitude_12co[i,:,:,0],\n",
    "        uncertainties=ordered_amplitude_12co[i,:,:,1],\n",
    "        header=maps_13co.mean[0].header,\n",
    "    )\n",
    "\n",
    "    column_densities.append(\n",
    "        src.hdu.maps.convenient_funcs.get_13co_column_density(\n",
    "            stddev_13co=stddev_13co,\n",
    "            antenna_temperature_13co=antenna_temperature_13co,\n",
    "            antenna_temperature_12co=antenna_temperature_12co\n",
    "        )\n",
    "    )\n",
    "    opacities.append(\n",
    "        src.hdu.maps.convenient_funcs.get_13co_opacity(\n",
    "            stddev_13co=stddev_13co,\n",
    "            antenna_temperature_13co=antenna_temperature_13co,\n",
    "            antenna_temperature_12co=antenna_temperature_12co,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# GroupedMaps([(\"column_density\", column_densities)]).save(\"data/Loop4/p/13co/p_column_density.fits\")\n",
    "# GroupedMaps([(\"opacity\", opacities)]).save(\"data/Loop4/p/13co/p_opacity.fits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H2 column density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_h2_column_density(\n",
    "    prefix: Literal[\"N1\", \"N2\", \"N4\", \"p\"],\n",
    "):\n",
    "    tess = Tesseract.load(f\"data/Loop4/{prefix}/12co/object_filtered.fits\")\n",
    "    cube = CubeCO.load(f\"data/Loop4/{prefix}/12co/Loop4{prefix}_wcs.fits\")\n",
    "    X_CO = 2.5e20\n",
    "    gm = tess.to_grouped_maps()\n",
    "    n_h2 = []\n",
    "    for amplitude, stddev in zip(gm.amplitude, gm.stddev):\n",
    "        n_h2.append(\n",
    "            src.hdu.maps.convenient_funcs.integrate_gaussian(\n",
    "                amplitude_map=amplitude,\n",
    "                stddev_map=stddev * np.abs(cube.header[\"CDELT3\"]) / 1000\n",
    "            ) * X_CO\n",
    "        )\n",
    "    GroupedMaps([(\"H2_column_density\", n_h2)])#.save(f\"data/Loop4/{prefix}/12co/{prefix}_H2_column_density.fits\")\n",
    "    Map(\n",
    "        data=np.nansum([m.data for m in n_h2], axis=0),\n",
    "        uncertainties=np.nansum([m.uncertainties for m in n_h2], axis=0),\n",
    "        header=n_h2[0].header,\n",
    "    ).num_to_nan()#.save(f\"data/Loop4/{prefix}/12co/{prefix}_H2_column_density_total.fits\")\n",
    "\n",
    "def calculate_h2_column_density_with_13co(\n",
    "        prefix: str,\n",
    "):\n",
    "    if prefix == \"p\":\n",
    "        column_densities = GroupedMaps.load(\"data/Loop4/p/13co/p_column_density.fits\").column_density\n",
    "        (2.2e6 * Map(\n",
    "            data=np.nansum([m.data for m in column_densities], axis=0),\n",
    "            uncertainties=np.nansum([m.uncertainties for m in column_densities], axis=0),\n",
    "            header=column_densities[0].header,\n",
    "        ).num_to_nan())#.save(f\"data/Loop4/{prefix}/13co/{prefix}_H2_column_density_total_13co.fits\")\n",
    "\n",
    "    else:\n",
    "        column_density = Map.load(f\"data/Loop4/{prefix}/13co/{prefix}_column_density.fits\")\n",
    "        (2.2e6 * column_density)#.save(f\"data/Loop4/{prefix}/13co/{prefix}_H2_column_density_total_13co.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_h2_column_density(\"N1\")\n",
    "calculate_h2_column_density(\"N2\")\n",
    "calculate_h2_column_density(\"N4\")\n",
    "calculate_h2_column_density(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_h2_column_density_with_13co(\"N1\")\n",
    "calculate_h2_column_density_with_13co(\"N2\")\n",
    "calculate_h2_column_density_with_13co(\"N4\")\n",
    "calculate_h2_column_density_with_13co(\"p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cloud_mass(\n",
    "    prefix: Literal[\"N1\", \"N2\", \"N4\", \"p\"],\n",
    "):\n",
    "    \"\"\"\n",
    "    Gives the cloud's mass in kg.\n",
    "    \"\"\"\n",
    "    alpha = 30 / 3600 * (2*np.pi)/360\n",
    "    if prefix in [\"N1\", \"p\"]:       # These two clouds were binned 2x2 whuch results in\n",
    "        alpha *= 2\n",
    "    D = 370 * scipy.constants.parsec * 100\n",
    "    mu = 2.4\n",
    "    m_H = scipy.constants.proton_mass + scipy.constants.electron_mass\n",
    "\n",
    "    n_h2 = Map.load(f\"data/Loop4/{prefix}/12co/{prefix}_H2_column_density_total.fits\")\n",
    "    sum_n_h2 = np.array([\n",
    "        np.nansum(n_h2.data),\n",
    "        np.nansum(n_h2.uncertainties),\n",
    "    ])\n",
    "    M = (alpha * D)**2 * mu * m_H * sum_n_h2\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = lambda x: f\"({x[0]:.5e} ± {x[1]:.5e})\"\n",
    "fm_solar = lambda x: f\"({x[0]/M_sun.value:.5e} ± {x[1]/M_sun.value:.5e})\"\n",
    "for cloud in [\"N1\", \"N2\", \"N4\", \"p\"]:\n",
    "    m = calculate_cloud_mass(cloud)\n",
    "    print(f\"Cloud {cloud:2}: M(H2)={fm(m):27} kg, M(CO)={fm(3e-6 * m):27} kg\")\n",
    "    print(f\"                {fm_solar(m):27} Ms, M(CO)={fm_solar(3e-6 * m):27} Ms\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertainties import ufloat\n",
    "\n",
    "cloud_masses = [[str(ufloat(*calculate_cloud_mass(cloud)) / 1e31), str(ufloat(*calculate_cloud_mass(cloud)) * 3e-6 / 1e26)]\n",
    "                for cloud in [\"N1\", \"N2\", \"N4\", \"p\"]]\n",
    "cloud_masses = [[s.replace(\"+/-\", \" ± \") for s in row] for row in cloud_masses]\n",
    "\n",
    "table_fig = gl.SmartFigure(\n",
    "    remove_axes=True,\n",
    "    size=(3.5, 2),\n",
    "    elements=[\n",
    "        gl.Table(\n",
    "            cell_text=cloud_masses,\n",
    "            col_labels=[\"M(H$_2$) [$10^{31}$ kg]\", \"M(CO) [$10^{26}$ kg]\"],\n",
    "            row_labels=[\"N1\", \"N2\", \"N4\", \"p\"],\n",
    "            cell_align=\"center\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "table_fig.show()\n",
    "# table_fig.save(\"figures/Loop4/second_results/cloud_masses.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphinglib as gl\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.wcs import WCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = CubeCO.load(\"data/Loop4/N1/12co/Loop4N1_wcs.fits\")[575:750,:,:]\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "fig.subplots_adjust(left=0.14, bottom=0.06, right=0.9, top=0.98, wspace=None, hspace=None)  # left, right, top, bottom\n",
    "header = cube.header\n",
    "ax = fig.add_subplot(111, projection=WCS(header.flatten(0)))\n",
    "anim = cube.data.plot_mpl(fig, ax,\n",
    "    cbar_limits=(0,10),\n",
    "    time_interval=30,\n",
    "    xlabel=\"Ascension droite\",\n",
    "    ylabel=\"Déclinaison\",\n",
    "    cbar_label=\"Intensité [u. arb.]\"\n",
    ")\n",
    "plt.show()\n",
    "# anim.save(\"figures/Loop4/Loop4N1_wcs.gif\", writer=\"imagemagick\", dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_speed = GroupedMaps.load(\"speed_maps/N1_speed.fits\").centroid_speed\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "fig.subplots_adjust(left=0.14, bottom=0.0, right=0.88, top=1.04, wspace=None, hspace=None)  # left, right, top, bottom\n",
    "header = m_speed[0].header\n",
    "ax = fig.add_subplot(111, projection=WCS(header.flatten(0)))\n",
    "cbar = plt.colorbar(ax.imshow(m_speed[0].data), fraction=0.057, pad=0.03)\n",
    "ax.tick_params(axis='both', direction='in')\n",
    "\n",
    "plt.xlabel(\"Ascension droite\")\n",
    "plt.ylabel(\"Déclinaison\")\n",
    "cbar.set_label(\"Vitesse des centroïdes [km s$^{-1}$]\")\n",
    "# %matplotlib inline\n",
    "# plt.show()\n",
    "plt.savefig(\"figures/Loop4/N1_speed.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_densities = GroupedMaps.load(\"data/Loop4/p/12co/p_H2_column_density.fits\").H2_column_density\n",
    "fig = plt.figure(figsize=(12,5.5))\n",
    "fig.subplots_adjust(left=0.07, bottom=0.05, right=0.9, top=1, wspace=0.3, hspace=None)  # left, right, top, bottom\n",
    "header = column_densities[0].header\n",
    "vmin, vmax = 1e19, 3e21\n",
    "axs = []\n",
    "\n",
    "for i, map_ in enumerate(column_densities[:-1]):\n",
    "    axs.append(fig.add_subplot(1, 3, i+1, projection=WCS(header)))\n",
    "    imshow = axs[-1].imshow(map_.data, vmin=vmin, vmax=vmax)\n",
    "    axs[-1].tick_params(axis='both', direction='in')\n",
    "    plt.xlabel(\" \")\n",
    "    plt.ylabel(\" \")\n",
    "\n",
    "cbar_ax = fig.add_axes([0.92, 0.155, 0.022, 0.75])\n",
    "cbar = fig.colorbar(imshow, cax=cbar_ax)\n",
    "\n",
    "fig.supxlabel(\"Ascension droite\", size=12)\n",
    "fig.supylabel(\"Déclinaison\")\n",
    "cbar.set_label(\"Densité de colonne du HI [cm $^{-2}$]\")\n",
    "# %matplotlib inline\n",
    "# plt.show()\n",
    "plt.savefig(\"figures/Loop4/column_density_HI_13co.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_densities = GroupedMaps.load(\"data/Loop4/p/13co/p_column_density.fits\").column_density\n",
    "fig = plt.figure(figsize=(8,5.5))\n",
    "fig.subplots_adjust(left=0.1, bottom=0.05, right=0.85, top=1, wspace=0.2, hspace=None)  # left, right, top, bottom\n",
    "header = column_densities[0].header\n",
    "vmin, vmax = 0, 4e14\n",
    "axs = []\n",
    "\n",
    "for i, map_ in enumerate(column_densities[:-1]):\n",
    "    axs.append(fig.add_subplot(1, 2, i+1, projection=WCS(header)))\n",
    "    imshow = axs[-1].imshow(map_.data, vmin=vmin, vmax=vmax)\n",
    "    axs[-1].tick_params(axis='both', direction='in')\n",
    "    plt.xlabel(\" \")\n",
    "    plt.ylabel(\" \")\n",
    "\n",
    "cbar_ax = fig.add_axes([0.90, 0.155, 0.022, 0.75])\n",
    "cbar = fig.colorbar(imshow, cax=cbar_ax)\n",
    "\n",
    "fig.supxlabel(\"Ascension droite\", size=12)\n",
    "fig.supylabel(\"Déclinaison\")\n",
    "cbar.set_label(\"Densité de colonne du $^{13}$CO [cm $^{-2}$]\")\n",
    "# %matplotlib inline\n",
    "# plt.show()\n",
    "plt.savefig(\"figures/Loop4/column_density_13co.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import src.graphinglib as gl\n",
    "import pyregion\n",
    "import warnings\n",
    "\n",
    "from src.hdu.maps.grouped_maps import GroupedMaps\n",
    "from src.hdu.maps.map import Map\n",
    "from src.hdu.cubes.cube_co import Cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kinetic temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = []\n",
    "for cloud, (i, j) in zip([\"N1\", \"N2\", \"N4\", \"p\"], [(1, 2), (1, 2), (1, 3), (2, 2)]):\n",
    "    cloud_heatmaps = []\n",
    "    maps = GroupedMaps.load(f\"data/Loop4/{cloud}/12co/kinetic_temperature.fits\").kinetic_temperature\n",
    "    for map_ in maps:\n",
    "        hm = map_.data.plot\n",
    "        hm.set_color_bar_params(label=\"Kinetic Temperature [K]\")\n",
    "        cloud_heatmaps.append(hm)\n",
    "    fig = gl.SmartFigureWCS(maps[0].header.wcs_object, i, j, x_label=\"Right Ascension\", y_label=\"Declination\",\n",
    "                            elements=cloud_heatmaps, size=(5*j, 4*i), aspect_ratio=\"auto\")\n",
    "    fig.set_ticks(number_of_x_ticks=4, minor_x_tick_frequency=5, minor_y_tick_frequency=5)\n",
    "    figs.append(fig)\n",
    "    fig.save(f\"figures/Loop4/first_results/{cloud}/kinetic_temperature.png\", dpi=600)\n",
    "\n",
    "for fig in figs:\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed map histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = []\n",
    "for cloud in [\"N1\", \"N2\", \"N4\", \"p\"]:\n",
    "    maps = GroupedMaps.load(f\"data/Loop4/speed_maps/{cloud}_speed.fits\").centroid_speed\n",
    "    hist = gl.Histogram(\n",
    "        data=np.concatenate([m.data[~np.isnan(m.data)] for m in maps]),\n",
    "        # data=np.concatenate([m.data.flatten() for m in maps]),\n",
    "        number_of_bins=20,\n",
    "        normalize=False,\n",
    "    )\n",
    "    fig = gl.SmartFigure(elements=[hist], title=cloud)\n",
    "    fig.set_ticks(x_tick_spacing=0.5)\n",
    "    figs.append(fig)\n",
    "fig = gl.SmartFigure(\n",
    "    2,\n",
    "    2,\n",
    "    elements=figs,\n",
    "    size=(10, 8),\n",
    "    x_label=\"Centroid Speed [km s$^{-1}$]\",\n",
    "    y_label=\"Number of Pixels [-]\"\n",
    ")\n",
    "fig[1,1].x_lim = (-2.2, 1.99)\n",
    "# fig.show()\n",
    "# fig.save(\"figures/Loop4/first_results/speed_histograms.png\", dpi=600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linewidths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = []\n",
    "for cloud, (i, j) in zip([\"N1\", \"N2\", \"N4\", \"p\"], [(1, 2), (1, 2), (1, 3), (2, 2)]):\n",
    "    cloud_heatmaps = []\n",
    "    cube_12co = CubeCO.load(f\"data/Loop4/{cloud}/12co/Loop4{cloud}_wcs.fits\")\n",
    "    maps_12co = Tesseract.load(f\"data/Loop4/{cloud}/12co/object_filtered.fits\").to_grouped_maps()\n",
    "    linewidths = [map_ * np.abs(cube_12co.header[\"CDELT3\"]/1000) * 2*np.sqrt(2*np.log(2)) for map_ in maps_12co.stddev]\n",
    "    for map_ in linewidths:\n",
    "        hm = map_.data.plot\n",
    "        hm.set_color_bar_params(label=\"Linewidth (FWHM) [km s$^{-1}$]\")\n",
    "        cloud_heatmaps.append(hm)\n",
    "    fig = gl.SmartFigureWCS(linewidths[0].header.wcs_object, i, j, x_label=\"Right Ascension\", y_label=\"Declination\",\n",
    "                            elements=cloud_heatmaps, size=(5*j, 4*i), aspect_ratio=\"auto\")\n",
    "    fig.set_ticks(number_of_x_ticks=4, minor_x_tick_frequency=5, minor_y_tick_frequency=5)\n",
    "    figs.append(fig)\n",
    "    # fig.save(f\"figures/Loop4/second_results/{cloud}/linewidths.png\", dpi=600)\n",
    "    # GroupedMaps([(\"linewidth\", linewidths)]).save(f\"figures/Loop4/second_results/{cloud}/linewidths.fits\")\n",
    "\n",
    "for fig in figs:\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = []\n",
    "for cloud in [\"N1\", \"N2\", \"N4\"]:\n",
    "    map_ = Map.load(f\"data/Loop4/{cloud}/13co/{cloud}_opacity.fits\")\n",
    "    hm = map_.data.plot\n",
    "    hm.set_color_bar_params(label=\"Opacity [-]\")\n",
    "    fig = gl.SmartFigureWCS(map_.header.wcs_object, 1, 1, x_label=\"Right Ascension\", y_label=\"Declination\",\n",
    "                            elements=[hm], size=(5, 4), aspect_ratio=\"auto\")\n",
    "    fig.set_ticks(number_of_x_ticks=3, minor_x_tick_frequency=5, minor_y_tick_frequency=5)\n",
    "    if cloud == \"N1\":\n",
    "        fig[0][0].color_map_range = 0.04, 0.31\n",
    "    figs.append(fig)\n",
    "    # fig.save(f\"figures/Loop4/second_results/{cloud}/opacity.png\", dpi=600)\n",
    "\n",
    "p_heatmaps = []\n",
    "p_maps = GroupedMaps.load(f\"data/Loop4/p/13co/p_opacity.fits\").opacity\n",
    "for map_ in p_maps:\n",
    "    hm = map_.data.plot\n",
    "    hm.set_color_bar_params(label=\"Opacity [-]\")\n",
    "    p_heatmaps.append(hm)\n",
    "fig = gl.SmartFigureWCS(p_maps[0].header.wcs_object, 1, 3, x_label=\"Right Ascension\", y_label=\"Declination\",\n",
    "                        elements=p_heatmaps, size=(12, 4), aspect_ratio=\"auto\")\n",
    "fig.set_ticks(number_of_x_ticks=4, minor_x_tick_frequency=5, minor_y_tick_frequency=5)\n",
    "figs.append(fig)\n",
    "# fig.save(f\"figures/Loop4/second_results/p/opacity.png\", dpi=600)\n",
    "\n",
    "for fig in figs:\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IR excess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column density with HI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_column_density(arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates the column density for each pixel in the given array. Each gaussian's area is computed using the error\n",
    "    function, and the total column density is obtained by summing the areas of all gaussians in each pixel.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : np.ndarray\n",
    "        A 4D array with shape (n_y, n_x, n_gaussians, 3), where the last dimension contains the amplitude, mean and\n",
    "        sigma of the gaussian.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        A 2D array with shape (n_y, n_x) containing the column density for each pixel, obtained by summing the gaussian\n",
    "        areas for each gaussian in the pixel.\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    applications/co/graph_gaussians/rohsa_gaussian.ipynb for more details on the formula used.\n",
    "    \"\"\"\n",
    "    column_densities = 1.82e18 * 2 * arr[:,:,:,0] * arr[:,:,:,2] * np.sqrt(np.pi/2)\n",
    "    return column_densities.sum(axis=2)\n",
    "\n",
    "def reshape_array(arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Reshapes the input 2D array to a 4D array with shape (n_y, n_x, n_gaussians, 3), where the last dimension contains\n",
    "    the amplitude, mean and sigma of the gaussian. The n_y and n_x sizes are inferred from the last element of the input\n",
    "    array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : np.ndarray\n",
    "        A 2D array corresponding to the output of the ROHSA program. Along the second axis, the first two elements are\n",
    "        y and x coordinates, and the rest are the parameters of the gaussian (amplitude, mean, sigma).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        A 4D array with shape (n_y, n_x, n_gaussians, 3), where the last dimension contains the amplitude, mean and\n",
    "        sigma of the gaussian.\n",
    "    \"\"\"\n",
    "    n_y, n_x = arr[-1,:2].astype(int) + 1\n",
    "    reshaped_arr = arr.reshape(arr.shape[0]//7, 7, -1)      # reshape to (n_pixels, 7, n_params)\n",
    "    reshaped_arr = reshaped_arr.reshape(n_y, n_x, 7, -1)    # (n_y, n_x, 7, n_params)\n",
    "    reshaped_arr = reshaped_arr[:, :, :, 2:]  # remove the first two parameters (y and x coordinates)\n",
    "    return reshaped_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", module=\"astropy.wcs.wcs\")\n",
    "\n",
    "# cube = Cube.load(\"data/HI/spider_hi.fits\").bin((1, 8, 8))\n",
    "# cube.save(\"data/HI/spider_hi_binned.fits\")\n",
    "cube = Cube.load(\"data/HI/spider_hi_binned.fits\")\n",
    "map_header = cube.header.flatten(0)\n",
    "# gl.SmartFigureWCS(projection=map_header.wcs_object, elements=[cube.data.plot]).show()\n",
    "\n",
    "background_data = np.loadtxt(\"data/HI/rohsa_fits/DF_gauss_run_0.dat\")\n",
    "background_column_density = Map(calculate_column_density(reshape_array(background_data)), header=map_header)\n",
    "regions = pyregion.open(\"data/HI/spiderZones_exact.reg\")\n",
    "regions_dict = {\n",
    "    \"sud\": (slice(113, 175), slice(30, 170)),\n",
    "    \"nord\": (slice(32, 88), slice(49, 163)),\n",
    "    \"coeur\": (slice(88, 113), slice(88, 113)),\n",
    "    \"est\": (slice(88, 113), slice(15, 88)),\n",
    "    \"ouest\": (slice(88, 113), slice(113, 201)),\n",
    "}\n",
    "for region_name, key in regions_dict.items():\n",
    "    region_data = np.loadtxt(f\"data/HI/rohsa_fits/DF_gauss_run_{region_name}.dat\")\n",
    "    region_column_density = calculate_column_density(reshape_array(region_data))\n",
    "    background_column_density.data[key] = region_column_density\n",
    "\n",
    "patches = regions.as_imagecoord(header=map_header).get_mpl_patches_texts()[0]\n",
    "polygons = [gl.Polygon(patch.get_xy()[:-1], fill=False, edge_color=patch.get_edgecolor()) for patch in patches]\n",
    "column_density_fig = gl.SmartFigureWCS(\n",
    "    projection=map_header.wcs_object,\n",
    "    x_label=\"Right Ascension\",\n",
    "    y_label=\"Declination\",\n",
    "    size=(8, 7),\n",
    "    elements=[\n",
    "        background_column_density.data.plot,\n",
    "        *polygons,\n",
    "    ],\n",
    ")\n",
    "column_density_fig[0][0].set_color_bar_params(label=\"Column density [$10^{20}$cm$^{-2}$]\")\n",
    "column_density_fig[0][0].color_map_range = (0.5e20, 9.5e20)\n",
    "column_density_fig[0][0].color_map = \"inferno\"\n",
    "column_density_fig.set_grid(show_on_top=True, line_width=1, color=\"white\")\n",
    "column_density_fig.set_tick_params(axis=\"both\", color=\"white\")\n",
    "column_density_fig.show()\n",
    "# background_column_density.save(\"data/HI/spider_hi_background_column_density_merged.fits\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IRIS mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_maps = [\n",
    "    Map.load(f\"data/HI/iris/{field}B4H0.fits\") for field in [\"I414\", \"I425\", \"I426\"]\n",
    "]\n",
    "for map_ in iris_maps:\n",
    "    for keyword in [\"CRVAL3\", \"CRPIX3\", \"CTYPE3\", \"CDELT3\"]:\n",
    "        if keyword in map_.header:\n",
    "            map_.header.remove(keyword)\n",
    "iris_maps_reprojected = [map_.get_reprojection_on(background_column_density.header) for map_ in iris_maps]\n",
    "iris_map = iris_maps_reprojected[0].copy()\n",
    "for map_ in iris_maps_reprojected[1:]:\n",
    "    iris_map.data[np.isnan(iris_map.data)] = map_.data[np.isnan(iris_map.data)]\n",
    "\n",
    "fig = gl.SmartFigure(elements=[iris_map.data.plot])\n",
    "fig[0][0].color_map_range = 0, 10\n",
    "fig.show()\n",
    "# iris_map.save(\"data/HI/iris_ir_excess.fits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iras IR excess map is obtained from https://irsa.ipac.caltech.edu/cgi-bin/ISSA/nph-issa?objstr=10%3A20%3A15+eq+73%3A55%3A25+eq&size=12.5+deg&iraspsc=1&coordinate_grid=1&band=4&submit=submit.\n",
    "\n",
    "The IRIS corrected maps are obtained from https://irsa.ipac.caltech.edu/cgi-bin/Atlas/nph-atlas?mission=IRIS&hdr_location=%2Fwork%2FTMP_WGRSaE_25947%2FAtlas%2F10h_20m_15.00s_%2B73d_55m_25.0s_Equ_J2000_25528.v0001&collection_desc=Improved+Reprocessing+of+the+IRAS+Survey+%28IRIS%29&region.x=200&region.y=218&locstr=10h+20m+15.00s+%2B73d+55m+25.0s+Equ+J2000&searchregion=&radius=6.25&regSize=12.5&covers=on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IR excess deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_ir_excess = Map.load(\"data/HI/iris_ir_excess.fits\")\n",
    "iris_ir_excess = iris_ir_excess.get_reprojection_on(map_header)\n",
    "iris_ir_excess_hm = iris_ir_excess.data.plot\n",
    "iris_ir_excess_hm.color_map = \"grey\"\n",
    "iris_ir_excess_hm.color_map_range = (0, 8)\n",
    "iris_ir_excess_hm.show_color_bar = False\n",
    "\n",
    "cropped_background = background_column_density.copy()\n",
    "cropped_background.data[cropped_background.data < 3e20] = np.nan\n",
    "\n",
    "superposed_fig = gl.SmartFigureWCS(\n",
    "    projection=map_header.wcs_object,\n",
    "    x_label=\"Right Ascension\",\n",
    "    y_label=\"Declination\",\n",
    "    size=(8, 7),\n",
    "    elements=[\n",
    "        iris_ir_excess_hm,\n",
    "        gl.Heatmap(\n",
    "            cropped_background.data / 1e20,\n",
    "            color_map=\"inferno\",\n",
    "            origin_position=\"lower\",\n",
    "            color_map_range=(0.5, 9.5),\n",
    "            alpha_value=1,\n",
    "            show_color_bar=True,\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "superposed_fig[0][1].set_color_bar_params(label=\"Column density [$10^{20}$cm$^{-2}$]\")\n",
    "# superposed_fig.set_grid(show_on_top=True, line_width=1, color=\"white\")\n",
    "# superposed_fig.set_tick_params(axis=\"both\", color=\"white\")\n",
    "superposed_fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_data = np.column_stack((background_column_density.data.flatten() / 1e20, iris_ir_excess.data.flatten()))\n",
    "scatter_data = scatter_data[np.argsort(scatter_data[:, 0])]\n",
    "scatter = gl.Scatter(\n",
    "    x_data=scatter_data[:,0],\n",
    "    y_data=scatter_data[:,1],\n",
    "    marker_size=0.7,\n",
    "    face_color=\"black\",\n",
    ")\n",
    "\n",
    "sigma_multiplier = 3\n",
    "lin_func = lambda x: 0.56 * x + 0.63\n",
    "fit = gl.Curve.from_function(lin_func, scatter.x_data.min(), scatter.x_data.max(),\n",
    "                             label=\"Reach et al. 1998 slope:\\n$y=0.56x+0.63$\")\n",
    "\n",
    "scatter_std_sample = scatter.create_slice_x(0, 2)\n",
    "threshold = np.std(scatter_std_sample.y_data - lin_func(scatter_std_sample.x_data)) * sigma_multiplier\n",
    "fit.add_error_curves(\n",
    "    threshold,\n",
    "    error_curves_line_style=\"--\",\n",
    ")\n",
    "\n",
    "background_column_density_cropped = background_column_density.copy() / 1e20\n",
    "excess_map = iris_ir_excess - lin_func(background_column_density / 1e20)\n",
    "background_column_density_cropped.data[excess_map.data < threshold] = np.nan\n",
    "\n",
    "fig = gl.SmartFigure(\n",
    "    2,\n",
    "    1,\n",
    "    elements=[\n",
    "        gl.SmartFigure(\n",
    "            x_label=\"Column density [10$^{20}$cm$^{-2}$]\",\n",
    "            y_label=r\"IRIS 100 $\\mu$m excess [MJy sr$^{-1}$]\",\n",
    "            elements=[scatter, fit],\n",
    "            y_lim=(0, 10),\n",
    "            x_lim=(0, None),\n",
    "        ),\n",
    "        gl.SmartFigureWCS(\n",
    "            projection=map_header.wcs_object,\n",
    "            elements=[\n",
    "                iris_ir_excess_hm,\n",
    "                background_column_density_cropped.data.plot,\n",
    "            ],\n",
    "            x_label=\"Right Ascension\",\n",
    "            y_label=\"Declination\",\n",
    "            aspect_ratio=\"equal\",\n",
    "        )\n",
    "    ],\n",
    "    size=(8, 10),\n",
    "    height_ratios=(1, 2),\n",
    ")\n",
    "fig[0].set_ticks(minor_x_tick_spacing=0.25, x_tick_spacing=1, minor_y_tick_spacing=0.5)\n",
    "fig[1][0][1].color_map = \"inferno\"\n",
    "fig[1][0][1].set_color_bar_params(label=\"Column density [$10^{20}$cm$^{-2}$]\")\n",
    "from matplotlib.lines import Line2D\n",
    "fig[0].set_custom_legend(\n",
    "    [Line2D([], [], linestyle=\"--\", label=rf\"$\\pm{sigma_multiplier}\\sigma$\", color=gl.get_color())]\n",
    ")\n",
    "fig.show()\n",
    "# fig.save(\"figures/HI/spider_hi_excess.png\", dpi=600)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
