{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kinetic temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kinetic temperature is obtained with the 12CO amplitude :\n",
    "$$T_{kin}=T_{x}=\\frac{5.532}{\\ln\\left(1+\\left(\\frac{T_A}{5.532}+0.151\\right)^{-1}\\right)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hdu.maps.map import Map\n",
    "from src.hdu.cubes.cube_co import CubeCO\n",
    "from src.hdu.tesseract import Tesseract\n",
    "from src.hdu.maps.grouped_maps import GroupedMaps\n",
    "from src.hdu.maps.convenient_funcs import get_kinetic_temperature\n",
    "from src.coordinates.ds9_coords import DS9Coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kinetic_temperature(prefix: str):\n",
    "    GroupedMaps([(\n",
    "        \"kinetic_temperature\", [\n",
    "            get_kinetic_temperature(amp) for amp in Tesseract.load(\n",
    "                f\"data/Loop4_co/{prefix}/12co/object_filtered.fits\"\n",
    "            ).to_grouped_maps().amplitude\n",
    "        ]\n",
    "    )]).save(f\"data/Loop4_co/{prefix}/12co/kinetic_temperature.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_kinetic_temperature(\"N1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_kinetic_temperature(\"N2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_kinetic_temperature(\"N4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_kinetic_temperature(\"p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column density is obtained using the following equation (Interstellar And Intergalactic Medium, Barbara Ryden and Richard W. Pogge) :\n",
    "\\begin{align*}\n",
    "    N_0\\left(^{13}\\text{CO}\\right)=\\int_{-\\infty}^\\infty T_A\\left(^{13}\\text{CO}\\right)\\cdot0.8\\cdot\\frac{g_0}{g_1A_{10}}\\cdot\\frac{\\pi k\\nu^2}{hc^3}\\left[\\left(\\frac1{\\exp\\left(\\frac{h\\nu}{kT_x}\\right)-1}-\\frac1{\\exp\\left(\\frac{h\\nu}{kT_{rad}}\\right)-1}\\right)\\left(1-\\exp\\left(-\\frac{h\\nu}{kT_x}\\right)\\right)\\right]^{-1}\n",
    "\\end{align*}\n",
    "knowing that\n",
    "\\begin{align*}\n",
    "    \\int_{-\\infty}^\\infty T_A\\left(^{13}\\text{CO}\\right)dv&=2T_A\\sigma\\sqrt{\\frac\\pi2}\\text{erf}\\left(\\frac{\\infty}{\\sqrt2\\sigma}\\right)\\\\\n",
    "    &=2T_A\\sigma\\sqrt{\\frac\\pi2}\\\\\n",
    "\\end{align*}\n",
    "as\n",
    "$$\\lim_{x\\rightarrow\\infty}\\text{erf}(x)=1$$\n",
    "we obtain\n",
    "$$N_0\\left(^{13}\\text{CO}\\right)=2T_A\\sigma\\sqrt{\\frac\\pi2}\\cdot0.8\\cdot\\frac{g_0}{g_1A_{10}}\\cdot\\frac{\\pi k\\nu^2}{hc^3}\\left[\\left(\\frac1{\\exp\\left(\\frac{h\\nu}{kT_x}\\right)-1}-\\frac1{\\exp\\left(\\frac{h\\nu}{kT_{rad}}\\right)-1}\\right)\\left(1-\\exp\\left(-\\frac{h\\nu}{kT_x}\\right)\\right)\\right]^{-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import graphinglib as gl\n",
    "import importlib\n",
    "import scipy\n",
    "\n",
    "import src.hdu.maps.convenient_funcs\n",
    "importlib.reload(src.hdu.maps.convenient_funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_single_component_column_density(prefix: str):\n",
    "    cube_12co = CubeCO.load(f\"data/Loop4_co/{prefix}/12co/Loop4{prefix}_wcs.fits\")\n",
    "    cube_13co = CubeCO.load(f\"data/Loop4_co/{prefix}/13co/Loop4{prefix}_13co.fits\")\n",
    "    maps_12co = Tesseract.load(f\"data/Loop4_co/{prefix}/12co/object_filtered.fits\").to_grouped_maps()\n",
    "    maps_13co = Tesseract.load(f\"data/Loop4_co/{prefix}/13co/tesseract.fits\").to_grouped_maps()\n",
    "\n",
    "    # The right gaussians first need to be selected\n",
    "    # This solution is for single component 13co maps\n",
    "    assert len(maps_13co.mean) == 1\n",
    "    mean_12co = np.stack([m.get_reprojection_on(maps_13co.mean[0]).data for m in maps_12co.mean], axis=0)\n",
    "    offset_12 = sum([int(line.split(\" \")[5][:-1]) if line[12:33] == \"was sliced at channel\" else 0 \n",
    "                     for line in maps_12co.mean[0].header[\"COMMENT\"]])\n",
    "    offset_13 = sum([int(line.split(\" \")[5][:-1]) if line[13:34] == \"was sliced at channel\" else 0 \n",
    "                     for line in maps_13co.mean[0].header[\"COMMENT\"]])\n",
    "\n",
    "    speed_convert_12 = np.vectorize(cube_12co.header.get_value)\n",
    "    speed_convert_13 = np.vectorize(cube_13co.header.get_value)\n",
    "    # Compute the diff between the centroid of every gaussian\n",
    "    diff_array = np.abs(speed_convert_12(mean_12co + offset_12)\n",
    "                      - speed_convert_13(maps_13co.mean[0].data + offset_13))\n",
    "    nan_mask = np.isnan(diff_array)     # Apply a nan mask to allow proper argmin use\n",
    "    diff_array[nan_mask] = 2**15-1      # Remove nans\n",
    "    min_mask = np.argmin(diff_array, axis=0)\n",
    "    filter_gaussians = lambda arr: np.take_along_axis(arr, min_mask[np.newaxis, ...], axis=0).squeeze()\n",
    "\n",
    "    amp_12co_val = np.stack(\n",
    "        [m.get_reprojection_on(maps_13co.mean[0]).data for m in maps_12co.amplitude], axis=0\n",
    "    )\n",
    "    amp_12co_unc = np.stack(\n",
    "        [m.get_reprojection_on(maps_13co.mean[0]).uncertainties for m in maps_12co.amplitude], axis=0\n",
    "    )\n",
    "\n",
    "    amplitude_correction_factor_13co = 0.43\n",
    "    src.hdu.maps.convenient_funcs.get_13co_column_density(\n",
    "        stddev_13co=maps_13co.stddev[0]*np.abs(cube_13co.header[\"CDELT3\"]/1000),\n",
    "        antenna_temperature_13co=maps_13co.amplitude[0]/amplitude_correction_factor_13co,\n",
    "        antenna_temperature_12co=Map(filter_gaussians(amp_12co_val), filter_gaussians(amp_12co_unc))\n",
    "    ).save(f\"data/Loop4_co/{prefix}/13co/{prefix}_column_density.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_single_component_column_density(\"N1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_single_component_column_density(\"N2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_single_component_column_density(\"N4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop4p multiple components\n",
    "import scipy.optimize\n",
    "\n",
    "cube_12co = CubeCO.load(\"data/Loop4_co/p/12co/Loop4p_wcs.fits\")\n",
    "cube_13co = CubeCO.load(\"data/Loop4_co/p/13co/Loop4p_13co.fits\")\n",
    "maps_12co = Tesseract.load(\"data/Loop4_co/p/12co/object_filtered.fits\").to_grouped_maps()\n",
    "maps_13co = Tesseract.load(\"data/Loop4_co/p/13co/object_filtered.fits\").to_grouped_maps()\n",
    "\n",
    "mean_12co = np.stack([m.get_reprojection_on(maps_13co.mean[0]).data for m in maps_12co.mean], axis=0)\n",
    "mean_13co = np.stack([m.data for m in maps_13co.mean], axis=0)\n",
    "ampl_12co_val = np.stack([m.get_reprojection_on(maps_13co.amplitude[0]).data for m in maps_12co.amplitude], axis=0)\n",
    "ampl_12co_unc = np.stack([m.get_reprojection_on(maps_13co.amplitude[0]).uncertainties for m in maps_12co.amplitude],\n",
    "                         axis=0)\n",
    "\n",
    "ordered_stddev_13co = np.full([*mean_13co.shape, 2], np.NAN)\n",
    "ordered_amplitude_13co = np.full([*mean_13co.shape, 2], np.NAN)\n",
    "ordered_amplitude_12co = np.full([*mean_13co.shape, 2], np.NAN)\n",
    "\n",
    "speed_convert_12 = np.vectorize(cube_12co.header.get_value)\n",
    "speed_convert_13 = np.vectorize(cube_13co.header.get_value)\n",
    "\n",
    "def minimize(target: np.ndarray, ref: np.ndarray):\n",
    "    \"\"\" \n",
    "    Minimizes the distance between two groups of points and gives the matching indices.\n",
    "    \"\"\"\n",
    "    # Create a cost matrix where the element at position (i, j) represents the difference between list1[i] and list2[j]\n",
    "    cost_matrix = np.abs(np.subtract.outer(target[~np.isnan(target)], ref[~np.isnan(ref)]))\n",
    "    # Use linear_sum_assignment to find the optimal assignment\n",
    "    row_indices, col_indices = scipy.optimize.linear_sum_assignment(cost_matrix)\n",
    "    # Create a list of tuples representing the pairs\n",
    "    pairs = list(zip(row_indices, col_indices))\n",
    "    # Check if the pairs are close enough, otherwise the pair is considered invalid\n",
    "    velocity_upper_limit = 100\n",
    "    valid_pairs = []\n",
    "    for pair in pairs:\n",
    "        if np.abs(target[pair[0]] - ref[pair[1]]) < velocity_upper_limit:\n",
    "            valid_pairs.append(pair)\n",
    "    return valid_pairs\n",
    "\n",
    "for y in range(mean_13co.shape[1]):\n",
    "    for x in range(mean_13co.shape[2]):\n",
    "        if not np.isnan(mean_13co[0,y,x]):\n",
    "            matches = minimize(speed_convert_13(mean_13co[:,y,x]+400), speed_convert_12(mean_12co[:,y,x]+500))\n",
    "            for match in matches:\n",
    "                ordered_stddev_13co[match[0],y,x] = [\n",
    "                    maps_13co.stddev[match[0]].data[y,x],\n",
    "                    maps_13co.stddev[match[0]].uncertainties[y,x]\n",
    "                ]\n",
    "                ordered_amplitude_13co[match[0],y,x] = [\n",
    "                    maps_13co.amplitude[match[0]].data[y,x],\n",
    "                    maps_13co.amplitude[match[0]].uncertainties[y,x]\n",
    "                ]\n",
    "                ordered_amplitude_12co[match[0],y,x] = [\n",
    "                    ampl_12co_val[match[1],y,x],\n",
    "                    ampl_12co_unc[match[1],y,x]\n",
    "                ]\n",
    "\n",
    "amplitude_correction_factor_13co = 0.43\n",
    "column_densities = []\n",
    "for i in range(mean_13co.shape[0]):\n",
    "    column_densities.append(\n",
    "        src.hdu.maps.convenient_funcs.get_13co_column_density(\n",
    "            stddev_13co=Map(\n",
    "                data=ordered_stddev_13co[i,:,:,0],\n",
    "                uncertainties=ordered_stddev_13co[i,:,:,1],\n",
    "                header=maps_13co.mean[0].header,\n",
    "            ) * np.abs(cube_13co.header[\"CDELT3\"]/1000),\n",
    "            antenna_temperature_13co=Map(\n",
    "                data=ordered_amplitude_13co[i,:,:,0],\n",
    "                uncertainties=ordered_amplitude_13co[i,:,:,1],\n",
    "                header=maps_13co.mean[0].header,\n",
    "            ) / amplitude_correction_factor_13co,\n",
    "            antenna_temperature_12co=Map(\n",
    "                data=ordered_amplitude_12co[i,:,:,0],\n",
    "                uncertainties=ordered_amplitude_12co[i,:,:,1],\n",
    "                header=maps_13co.mean[0].header,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "GroupedMaps([(\"column_density\", column_densities)]).save(\"data/Loop4_co/p/13co/p_column_density.fits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.coordinates.ds9_coords import DS9Coords\n",
    "\n",
    "coords = DS9Coords(28,20)\n",
    "h_coords = DS9Coords(14,10)\n",
    "\n",
    "spec_1 = CubeCO.load(\"data/Loop4_co/N1/12co/Loop4N1_wcs.fits\")[500:800,*coords]\n",
    "spec_2 = CubeCO.load(\"data/Loop4_co/N1/13co/Loop4N1_13co_corrected.fits\")[:,*coords]\n",
    "\n",
    "fig = gl.Figure()\n",
    "# fig.add_elements(*Tesseract.load(\"data/Loop4_co/N1/12co/object_filtered.fits\").get_spectrum_plot(cube_12co.bin((1,2,2))[500:800,:,:], h_coords))\n",
    "fig.add_elements(*Tesseract.load(\"data/Loop4_co/N1/13co/tesseract.fits\").get_spectrum_plot(cube_13co, coords))\n",
    "# %matplotlib tk\n",
    "# fig.show()\n",
    "\n",
    "# fig = gl.Figure()\n",
    "# fig.add_elements(spec_1.plot)\n",
    "# fig.show()\n",
    "# fig = gl.Figure()\n",
    "# fig.add_elements(spec_2.plot)\n",
    "# fig.show()\n",
    "a_12co = 6.43\n",
    "a_13co = 1.03\n",
    "s_13co = 8.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_12 = Tesseract.load(\"data/Loop4_co/N1/12co/object_filtered.fits\")#.data[:,0,*DS9Coords(13,14)]\n",
    "co_13 = Tesseract.load(\"data/Loop4_co/N1/13co/tesseract.fits\")#.data[:,0,*DS9Coords(13,14)]\n",
    "\n",
    "co_12_s = co_12.data[:,0,*DS9Coords(13,14)]\n",
    "co_13_s = co_13.data[:,0,*DS9Coords(13,14)]\n",
    "\n",
    "fig = gl.Figure()\n",
    "fig.add_elements(*co_12.get_spectrum_plot(CubeCO.load(\"data/Loop4_co/N1/12co/Loop4N1_wcs_bin2.fits\"), DS9Coords(13,14)))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_12_cube = CubeCO.load(\"data/Loop4_co/N1/12co/Loop4N1_wcs.fits\")#.data[:,0,*DS9Coords(13,14)]\n",
    "co_13_cube = CubeCO.load(\"data/Loop4_co/N1/13co/Loop4N1_13co_corrected.fits\")#.data[:,0,*DS9Coords(13,14)]\n",
    "\n",
    "print(\"12CO\")\n",
    "fig = gl.Figure()\n",
    "fig.add_elements(co_12_cube[675:750,*DS9Coords(28,19)].plot)\n",
    "fig.show()\n",
    "print(\"13CO\")\n",
    "fig = gl.Figure()\n",
    "fig.add_elements(co_13_cube[175:225,*DS9Coords(28,19)].plot)\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
