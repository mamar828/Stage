{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kinetic temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kinetic temperature is obtained with the 12CO amplitude :\n",
    "$$T_{kin}=T_{x}=\\frac{5.532}{\\ln\\left(1+\\left(\\frac{T_A}{5.532}+0.151\\right)^{-1}\\right)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hdu.maps.map import Map\n",
    "from src.hdu.cubes.cube_co import CubeCO\n",
    "from src.hdu.tesseract import Tesseract\n",
    "from src.hdu.maps.grouped_maps import GroupedMaps\n",
    "from src.hdu.maps.convenient_funcs import get_kinetic_temperature\n",
    "from src.coordinates.ds9_coords import DS9Coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kinetic_temperature(prefix: str):\n",
    "    GroupedMaps([(\n",
    "        \"kinetic_temperature\", [\n",
    "            get_kinetic_temperature(amp) for amp in Tesseract.load(\n",
    "                f\"data/Loop4_co/{prefix}/12co/object_filtered.fits\"\n",
    "            ).to_grouped_maps().amplitude\n",
    "        ]\n",
    "    )])#.save(f\"data/Loop4_co/{prefix}/12co/kinetic_temperature.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_kinetic_temperature(\"N1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_kinetic_temperature(\"N2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_kinetic_temperature(\"N4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_kinetic_temperature(\"p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column density is obtained using the following equation (Interstellar And Intergalactic Medium, Barbara Ryden and Richard W. Pogge):\n",
    "\\begin{align*}\n",
    "    N_0\\left(^{13}\\text{CO}\\right)=\\int_{-\\infty}^\\infty T_A\\left(^{13}\\text{CO}\\right)dv\\cdot0.8\\cdot\\frac{g_0}{g_1A_{10}}\\cdot\\frac{\\pi k\\nu^2}{hc^3}\\left[\\left(\\frac1{\\exp\\left(\\frac{h\\nu}{kT_x}\\right)-1}-\\frac1{\\exp\\left(\\frac{h\\nu}{kT_{rad}}\\right)-1}\\right)\\left(1-\\exp\\left(-\\frac{h\\nu}{kT_x}\\right)\\right)\\right]^{-1}\n",
    "\\end{align*}\n",
    "knowing that\n",
    "\\begin{align*}\n",
    "    \\int_{-\\infty}^\\infty T_A\\left(^{13}\\text{CO}\\right)dv&=2T_A\\sigma\\sqrt{\\frac\\pi2}\\text{erf}\\left(\\frac{\\infty}{\\sqrt2\\sigma}\\right)\\\\\n",
    "    &=2T_A\\sigma\\sqrt{\\frac\\pi2}\\\\\n",
    "\\end{align*}\n",
    "as\n",
    "$$\\lim_{x\\rightarrow\\infty}\\text{erf}(x)=1$$\n",
    "we obtain\n",
    "$$N_0\\left(^{13}\\text{CO}\\right)=2T_A\\sigma\\sqrt{\\frac\\pi2}\\cdot0.8\\cdot\\frac{g_0}{g_1A_{10}}\\cdot\\frac{\\pi k\\nu^2}{hc^3}\\left[\\left(\\frac1{\\exp\\left(\\frac{h\\nu}{kT_x}\\right)-1}-\\frac1{\\exp\\left(\\frac{h\\nu}{kT_{rad}}\\right)-1}\\right)\\left(1-\\exp\\left(-\\frac{h\\nu}{kT_x}\\right)\\right)\\right]^{-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import graphinglib as gl\n",
    "import importlib\n",
    "import scipy\n",
    "from astropy.constants import M_sun\n",
    "\n",
    "import src.hdu.maps.convenient_funcs\n",
    "# importlib.reload(src.hdu.maps.convenient_funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_single_component_column_density(prefix: str):\n",
    "    cube_12co = CubeCO.load(f\"data/Loop4_co/{prefix}/12co/Loop4{prefix}_wcs.fits\")\n",
    "    cube_13co = CubeCO.load(f\"data/Loop4_co/{prefix}/13co/Loop4{prefix}_13co.fits\")\n",
    "    maps_12co = Tesseract.load(f\"data/Loop4_co/{prefix}/12co/object_filtered.fits\").to_grouped_maps()\n",
    "    maps_13co = Tesseract.load(f\"data/Loop4_co/{prefix}/13co/tesseract.fits\").to_grouped_maps()\n",
    "\n",
    "    # The right gaussians first need to be selected\n",
    "    # This solution is for single component 13co maps\n",
    "    assert len(maps_13co.mean) == 1\n",
    "    mean_12co = np.stack([m.get_reprojection_on(maps_13co.mean[0]).data for m in maps_12co.mean], axis=0)\n",
    "    offset_12 = sum([int(line.split(\" \")[5][:-1]) if line[12:33] == \"was sliced at channel\" else 0\n",
    "                     for line in maps_12co.mean[0].header[\"COMMENT\"]])\n",
    "    offset_13 = sum([int(line.split(\" \")[5][:-1]) if line[13:34] == \"was sliced at channel\" else 0\n",
    "                     for line in maps_13co.mean[0].header[\"COMMENT\"]])\n",
    "\n",
    "    speed_convert_12 = np.vectorize(cube_12co.header.get_value)\n",
    "    speed_convert_13 = np.vectorize(cube_13co.header.get_value)\n",
    "    # Compute the diff between the centroid of every gaussian\n",
    "    diff_array = np.abs(speed_convert_12(mean_12co + offset_12)\n",
    "                      - speed_convert_13(maps_13co.mean[0].data + offset_13))\n",
    "    nan_mask = np.isnan(diff_array)     # Apply a nan mask to allow proper argmin use\n",
    "    diff_array[nan_mask] = 2**15-1      # Remove nans\n",
    "    min_mask = np.argmin(diff_array, axis=0)\n",
    "    filter_gaussians = lambda arr: np.take_along_axis(arr, min_mask[np.newaxis, ...], axis=0).squeeze()\n",
    "\n",
    "    amp_12co_val = np.stack(\n",
    "        [m.get_reprojection_on(maps_13co.mean[0]).data for m in maps_12co.amplitude], axis=0\n",
    "    )\n",
    "    amp_12co_unc = np.stack(\n",
    "        [m.get_reprojection_on(maps_13co.mean[0]).uncertainties for m in maps_12co.amplitude], axis=0\n",
    "    )\n",
    "\n",
    "    amplitude_correction_factor_13co = 0.43\n",
    "    src.hdu.maps.convenient_funcs.get_13co_column_density(\n",
    "        stddev_13co=maps_13co.stddev[0]*np.abs(cube_13co.header[\"CDELT3\"]/1000),\n",
    "        antenna_temperature_13co=maps_13co.amplitude[0]/amplitude_correction_factor_13co,\n",
    "        antenna_temperature_12co=Map(filter_gaussians(amp_12co_val), filter_gaussians(amp_12co_unc))\n",
    "    )#.save(f\"data/Loop4_co/{prefix}/13co/{prefix}_column_density.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_single_component_column_density(\"N1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_single_component_column_density(\"N2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_single_component_column_density(\"N4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop4p multiple components\n",
    "import scipy.optimize\n",
    "\n",
    "cube_12co = CubeCO.load(\"data/Loop4_co/p/12co/Loop4p_wcs.fits\")\n",
    "cube_13co = CubeCO.load(\"data/Loop4_co/p/13co/Loop4p_13co.fits\")\n",
    "maps_12co = Tesseract.load(\"data/Loop4_co/p/12co/object_filtered.fits\").to_grouped_maps()\n",
    "maps_13co = Tesseract.load(\"data/Loop4_co/p/13co/object_filtered.fits\").to_grouped_maps()\n",
    "\n",
    "mean_12co = np.stack([m.get_reprojection_on(maps_13co.mean[0]).data for m in maps_12co.mean], axis=0)\n",
    "mean_13co = np.stack([m.data for m in maps_13co.mean], axis=0)\n",
    "ampl_12co_val = np.stack([m.get_reprojection_on(maps_13co.amplitude[0]).data for m in maps_12co.amplitude], axis=0)\n",
    "ampl_12co_unc = np.stack([m.get_reprojection_on(maps_13co.amplitude[0]).uncertainties for m in maps_12co.amplitude],\n",
    "                         axis=0)\n",
    "\n",
    "ordered_stddev_13co = np.full([*mean_13co.shape, 2], np.NAN)\n",
    "ordered_amplitude_13co = np.full([*mean_13co.shape, 2], np.NAN)\n",
    "ordered_amplitude_12co = np.full([*mean_13co.shape, 2], np.NAN)\n",
    "\n",
    "speed_convert_12 = np.vectorize(cube_12co.header.get_value)\n",
    "speed_convert_13 = np.vectorize(cube_13co.header.get_value)\n",
    "\n",
    "def minimize(target: np.ndarray, ref: np.ndarray):\n",
    "    \"\"\"\n",
    "    Minimizes the distance between two groups of points and gives the matching indices.\n",
    "    \"\"\"\n",
    "    # Create a cost matrix where the element at position (i, j) represents the difference between list1[i] and list2[j]\n",
    "    cost_matrix = np.abs(np.subtract.outer(target[~np.isnan(target)], ref[~np.isnan(ref)]))\n",
    "    # Use linear_sum_assignment to find the optimal assignment\n",
    "    row_indices, col_indices = scipy.optimize.linear_sum_assignment(cost_matrix)\n",
    "    # Create a list of tuples representing the pairs\n",
    "    pairs = list(zip(row_indices, col_indices))\n",
    "    # Check if the pairs are close enough, otherwise the pair is considered invalid\n",
    "    velocity_upper_limit = 100\n",
    "    valid_pairs = []\n",
    "    for pair in pairs:\n",
    "        if np.abs(target[pair[0]] - ref[pair[1]]) < velocity_upper_limit:\n",
    "            valid_pairs.append(pair)\n",
    "    return valid_pairs\n",
    "\n",
    "for y in range(mean_13co.shape[1]):\n",
    "    for x in range(mean_13co.shape[2]):\n",
    "        if not np.isnan(mean_13co[0,y,x]):\n",
    "            matches = minimize(speed_convert_13(mean_13co[:,y,x]+400), speed_convert_12(mean_12co[:,y,x]+500))\n",
    "            for match in matches:\n",
    "                ordered_stddev_13co[match[0],y,x] = [\n",
    "                    maps_13co.stddev[match[0]].data[y,x],\n",
    "                    maps_13co.stddev[match[0]].uncertainties[y,x]\n",
    "                ]\n",
    "                ordered_amplitude_13co[match[0],y,x] = [\n",
    "                    maps_13co.amplitude[match[0]].data[y,x],\n",
    "                    maps_13co.amplitude[match[0]].uncertainties[y,x]\n",
    "                ]\n",
    "                ordered_amplitude_12co[match[0],y,x] = [\n",
    "                    ampl_12co_val[match[1],y,x],\n",
    "                    ampl_12co_unc[match[1],y,x]\n",
    "                ]\n",
    "\n",
    "amplitude_correction_factor_13co = 0.43\n",
    "column_densities = []\n",
    "for i in range(mean_13co.shape[0]):\n",
    "    column_densities.append(\n",
    "        src.hdu.maps.convenient_funcs.get_13co_column_density(\n",
    "            stddev_13co=Map(\n",
    "                data=ordered_stddev_13co[i,:,:,0],\n",
    "                uncertainties=ordered_stddev_13co[i,:,:,1],\n",
    "                header=maps_13co.mean[0].header,\n",
    "            ) * np.abs(cube_13co.header[\"CDELT3\"]/1000),\n",
    "            antenna_temperature_13co=Map(\n",
    "                data=ordered_amplitude_13co[i,:,:,0],\n",
    "                uncertainties=ordered_amplitude_13co[i,:,:,1],\n",
    "                header=maps_13co.mean[0].header,\n",
    "            ) / amplitude_correction_factor_13co,\n",
    "            antenna_temperature_12co=Map(\n",
    "                data=ordered_amplitude_12co[i,:,:,0],\n",
    "                uncertainties=ordered_amplitude_12co[i,:,:,1],\n",
    "                header=maps_13co.mean[0].header,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "# GroupedMaps([(\"column_density\", column_densities)]).save(\"data/Loop4_co/p/13co/p_column_density.fits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H2 column density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_h2_column_density(\n",
    "    prefix: str,\n",
    "):\n",
    "    tess = Tesseract.load(f\"data/Loop4_co/{prefix}/12co/object_filtered.fits\")\n",
    "    cube = CubeCO.load(f\"data/Loop4_co/{prefix}/12co/Loop4{prefix}_wcs.fits\")\n",
    "    X_CO = 2.5e20\n",
    "    gm = tess.to_grouped_maps()\n",
    "    n_h2 = []\n",
    "    for amplitude, stddev in zip(gm.amplitude, gm.stddev):\n",
    "        n_h2.append(\n",
    "            src.hdu.maps.convenient_funcs.integrate_gaussian(\n",
    "                amplitude_map=amplitude,\n",
    "                stddev_map=stddev * np.abs(cube.header[\"CDELT3\"]) / 1000\n",
    "            ) * X_CO\n",
    "        )\n",
    "    GroupedMaps([(\"H2_column_density\", n_h2)])#.save(f\"data/Loop4_co/{prefix}/12co/{prefix}_H2_column_density.fits\")\n",
    "    Map(\n",
    "        data=np.nansum([m.data for m in n_h2], axis=0),\n",
    "        uncertainties=np.nansum([m.uncertainties for m in n_h2], axis=0),\n",
    "        header=n_h2[0].header,\n",
    "    ).num_to_nan()#.save(f\"data/Loop4_co/{prefix}/12co/{prefix}_H2_column_density_total.fits\")\n",
    "\n",
    "def calculate_h2_column_density_with_13co(\n",
    "        prefix: str,\n",
    "):\n",
    "    if prefix == \"p\":\n",
    "        column_densities = GroupedMaps.load(\"data/Loop4_co/p/13co/p_column_density.fits\").column_density\n",
    "        (2.2e6 * Map(\n",
    "            data=np.nansum([m.data for m in column_densities], axis=0),\n",
    "            uncertainties=np.nansum([m.uncertainties for m in column_densities], axis=0),\n",
    "            header=column_densities[0].header,\n",
    "        ).num_to_nan())#.save(f\"data/Loop4_co/{prefix}/13co/{prefix}_H2_column_density_total_13co.fits\")\n",
    "\n",
    "    else:\n",
    "        column_density = Map.load(f\"data/Loop4_co/{prefix}/13co/{prefix}_column_density.fits\")\n",
    "        (2.2e6 * column_density)#.save(f\"data/Loop4_co/{prefix}/13co/{prefix}_H2_column_density_total_13co.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_h2_column_density(\"N1\")\n",
    "calculate_h2_column_density(\"N2\")\n",
    "calculate_h2_column_density(\"N4\")\n",
    "calculate_h2_column_density(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_h2_column_density_with_13co(\"N1\")\n",
    "calculate_h2_column_density_with_13co(\"N2\")\n",
    "calculate_h2_column_density_with_13co(\"N4\")\n",
    "calculate_h2_column_density_with_13co(\"p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cloud_mass(\n",
    "        prefix: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Gives the cloud's mass in kg.\n",
    "    \"\"\"\n",
    "    alpha = 30 / 3600 * (2*np.pi)/360\n",
    "    if prefix in [\"N1\", \"p\"]:       # These two clouds were binned 2x2 whuch results in\n",
    "        alpha *= 2\n",
    "    D = 370 * scipy.constants.parsec * 100\n",
    "    mu = 2.4\n",
    "    m_H = scipy.constants.proton_mass + scipy.constants.electron_mass\n",
    "\n",
    "    n_h2 = Map.load(f\"data/Loop4_co/{prefix}/12co/{prefix}_H2_column_density_total.fits\")\n",
    "    sum_n_h2 = np.array([\n",
    "        np.nansum(n_h2.data),\n",
    "        np.nansum(n_h2.uncertainties),\n",
    "    ])\n",
    "    M = (alpha * D)**2 * mu * m_H * sum_n_h2\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = lambda x: f\"({x[0]:.5e} ± {x[1]:.5e})\"\n",
    "fm_solar = lambda x: f\"({x[0]/M_sun.value:.5e} ± {x[1]/M_sun.value:.5e})\"\n",
    "for cloud in [\"N1\", \"N2\", \"N4\", \"p\"]:\n",
    "    m = calculate_cloud_mass(cloud)\n",
    "    print(f\"Cloud {cloud:2}: M(H2)={fm(m):27} kg, M(CO)={fm(3e-6 * m):27} kg\")\n",
    "    print(f\"                {fm_solar(m):27} Ms, M(CO)={fm_solar(3e-6 * m):27} Ms\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphinglib as gl\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.wcs import WCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = CubeCO.load(\"data/Loop4_co/N1/12co/Loop4N1_wcs.fits\")[575:750,:,:]\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "fig.subplots_adjust(left=0.14, bottom=0.06, right=0.9, top=0.98, wspace=None, hspace=None)  # left, right, top, bottom\n",
    "header = cube.header\n",
    "ax = fig.add_subplot(111, projection=WCS(header.flatten(0)))\n",
    "anim = cube.data.plot_mpl(fig, ax,\n",
    "    cbar_limits=(0,10),\n",
    "    time_interval=30,\n",
    "    xlabel=\"Ascension droite\",\n",
    "    ylabel=\"Déclinaison\",\n",
    "    cbar_label=\"Intensité [u. arb.]\"\n",
    ")\n",
    "plt.show()\n",
    "# anim.save(\"figures/Loop4/Loop4N1_wcs.gif\", writer=\"imagemagick\", dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_speed = GroupedMaps.load(\"speed_maps/N1_speed.fits\").centroid_speed\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "fig.subplots_adjust(left=0.14, bottom=0.0, right=0.88, top=1.04, wspace=None, hspace=None)  # left, right, top, bottom\n",
    "header = m_speed[0].header\n",
    "ax = fig.add_subplot(111, projection=WCS(header.flatten(0)))\n",
    "cbar = plt.colorbar(ax.imshow(m_speed[0].data), fraction=0.057, pad=0.03)\n",
    "ax.tick_params(axis='both', direction='in')\n",
    "\n",
    "plt.xlabel(\"Ascension droite\")\n",
    "plt.ylabel(\"Déclinaison\")\n",
    "cbar.set_label(\"Vitesse des centroïdes [km s$^{-1}$]\")\n",
    "# %matplotlib inline\n",
    "# plt.show()\n",
    "plt.savefig(\"figures/Loop4/N1_speed.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_densities = GroupedMaps.load(\"data/Loop4_co/p/12co/p_H2_column_density.fits\").H2_column_density\n",
    "fig = plt.figure(figsize=(12,5.5))\n",
    "fig.subplots_adjust(left=0.07, bottom=0.05, right=0.9, top=1, wspace=0.3, hspace=None)  # left, right, top, bottom\n",
    "header = column_densities[0].header\n",
    "vmin, vmax = 1e19, 3e21\n",
    "axs = []\n",
    "\n",
    "for i, map_ in enumerate(column_densities[:-1]):\n",
    "    axs.append(fig.add_subplot(1, 3, i+1, projection=WCS(header)))\n",
    "    imshow = axs[-1].imshow(map_.data, vmin=vmin, vmax=vmax)\n",
    "    axs[-1].tick_params(axis='both', direction='in')\n",
    "    plt.xlabel(\" \")\n",
    "    plt.ylabel(\" \")\n",
    "\n",
    "cbar_ax = fig.add_axes([0.92, 0.155, 0.022, 0.75])\n",
    "cbar = fig.colorbar(imshow, cax=cbar_ax)\n",
    "\n",
    "fig.supxlabel(\"Ascension droite\", size=12)\n",
    "fig.supylabel(\"Déclinaison\")\n",
    "cbar.set_label(\"Densité de colonne du HI [cm $^{-2}$]\")\n",
    "# %matplotlib inline\n",
    "# plt.show()\n",
    "plt.savefig(\"figures/Loop4/column_density_HI_13co.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_densities = GroupedMaps.load(\"data/Loop4_co/p/13co/p_column_density.fits\").column_density\n",
    "fig = plt.figure(figsize=(8,5.5))\n",
    "fig.subplots_adjust(left=0.1, bottom=0.05, right=0.85, top=1, wspace=0.2, hspace=None)  # left, right, top, bottom\n",
    "header = column_densities[0].header\n",
    "vmin, vmax = 0, 4e14\n",
    "axs = []\n",
    "\n",
    "for i, map_ in enumerate(column_densities[:-1]):\n",
    "    axs.append(fig.add_subplot(1, 2, i+1, projection=WCS(header)))\n",
    "    imshow = axs[-1].imshow(map_.data, vmin=vmin, vmax=vmax)\n",
    "    axs[-1].tick_params(axis='both', direction='in')\n",
    "    plt.xlabel(\" \")\n",
    "    plt.ylabel(\" \")\n",
    "\n",
    "cbar_ax = fig.add_axes([0.90, 0.155, 0.022, 0.75])\n",
    "cbar = fig.colorbar(imshow, cax=cbar_ax)\n",
    "\n",
    "fig.supxlabel(\"Ascension droite\", size=12)\n",
    "fig.supylabel(\"Déclinaison\")\n",
    "cbar.set_label(\"Densité de colonne du $^{13}$CO [cm $^{-2}$]\")\n",
    "# %matplotlib inline\n",
    "# plt.show()\n",
    "plt.savefig(\"figures/Loop4/column_density_13co.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import src.graphinglib as gl\n",
    "\n",
    "from src.hdu.maps.grouped_maps import GroupedMaps\n",
    "from src.hdu.maps.map import Map\n",
    "from src.hdu.cubes.cube_co import Cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kinetic temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = []\n",
    "for cloud, (i, j) in zip([\"N1\", \"N2\", \"N4\", \"p\"], [(1, 2), (1, 2), (1, 3), (2, 2)]):\n",
    "    cloud_heatmaps = []\n",
    "    maps = GroupedMaps.load(f\"data/Loop4/{cloud}/12co/kinetic_temperature.fits\").kinetic_temperature\n",
    "    for map_ in maps:\n",
    "        hm = map_.data.plot\n",
    "        hm.set_color_bar_params(label=\"Kinetic Temperature [K]\")\n",
    "        cloud_heatmaps.append(hm)\n",
    "    fig = gl.SmartFigureWCS(maps[0].header.wcs_object, i, j, x_label=\"Right Ascension\", y_label=\"Declination\",\n",
    "                            elements=cloud_heatmaps, size=(5*j, 4*i), aspect_ratio=\"auto\")\n",
    "    fig.set_ticks(number_of_x_ticks=4, minor_x_tick_frequency=5, minor_y_tick_frequency=5)\n",
    "    figs.append(fig)\n",
    "    fig.save(f\"figures/Loop4/first_results/{cloud}/kinetic_temperature.png\", dpi=600)\n",
    "\n",
    "for fig in figs:\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed map histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = []\n",
    "for cloud in [\"N1\", \"N2\", \"N4\", \"p\"]:\n",
    "    maps = GroupedMaps.load(f\"data/Loop4/speed_maps/{cloud}_speed.fits\").centroid_speed\n",
    "    hist = gl.Histogram(\n",
    "        data=np.concatenate([m.data[~np.isnan(m.data)] for m in maps]),\n",
    "        # data=np.concatenate([m.data.flatten() for m in maps]),\n",
    "        number_of_bins=20,\n",
    "        normalize=False,\n",
    "    )\n",
    "    fig = gl.SmartFigure(elements=[hist], title=cloud)\n",
    "    fig.set_ticks(x_tick_spacing=0.5)\n",
    "    figs.append(fig)\n",
    "fig = gl.SmartFigure(\n",
    "    2,\n",
    "    2,\n",
    "    elements=figs,\n",
    "    size=(10, 8),\n",
    "    x_label=\"Centroid Speed [km s$^{-1}$]\",\n",
    "    y_label=\"Number of Pixels [-]\"\n",
    ")\n",
    "fig[1,1].x_lim = (-2.2, 1.99)\n",
    "# fig.show()\n",
    "# fig.save(\"figures/Loop4/first_results/speed_histograms.png\", dpi=600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IR excess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_column_density(arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates the column density for each pixel in the given array. Each gaussian's area is computed using the error\n",
    "    function, and the total column density is obtained by summing the areas of all gaussians in each pixel.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : np.ndarray\n",
    "        A 4D array with shape (n_y, n_x, n_gaussians, 3), where the last dimension contains the amplitude, mean and\n",
    "        sigma of the gaussian.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        A 2D array with shape (n_y, n_x) containing the column density for each pixel, obtained by summing the gaussian\n",
    "        areas for each gaussian in the pixel.\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    applications/co/graph_gaussians/rohsa_gaussian.ipynb for more details on the formula used.\n",
    "    \"\"\"\n",
    "    column_densities = 1.82e18 * 2 * arr[:,:,:,0] * arr[:,:,:,2] * np.sqrt(np.pi/2)\n",
    "    return column_densities.sum(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cube = Cube.load(\"data/HI_data/spider_hi.fits\").bin((1, 8, 8))\n",
    "# cube.save(\"data/HI_data/spider_hi_binned.fits\")\n",
    "cube = Cube.load(\"data/HI_data/spider_hi_binned.fits\")\n",
    "# gl.SmartFigureWCS(projection=cube.header.flatten(0).wcs_object, elements=[cube.data.plot]).show()\n",
    "\n",
    "background_data = np.loadtxt(\"data/HI_data/DF_gauss_run_0.dat\")\n",
    "background_data = background_data.reshape(background_data.shape[0]//7, 7, -1)       # reshape to (n_pixels, 7, n_params)\n",
    "background_data = background_data.reshape(cube.data.shape[1], cube.data.shape[2], 7, -1)    # (n_y, n_x, 7, n_params)\n",
    "background_data = background_data[:, :, :, 2:]  # remove the first two parameters (y and x coordinates)\n",
    "background_column_density = calculate_column_density(background_data)\n",
    "\n",
    "column_density_fig = gl.SmartFigureWCS(\n",
    "    projection=cube.header.flatten(0).wcs_object,\n",
    "    x_label=\"Right Ascension\",\n",
    "    y_label=\"Declination\",\n",
    "    size=(8, 7),\n",
    "    elements=[\n",
    "        gl.Heatmap(\n",
    "            background_column_density,\n",
    "            color_map=\"inferno\",\n",
    "            origin_position=\"lower\",\n",
    "            color_map_range=(0.5e20, 9.5e20),\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "column_density_fig.set_grid(show_on_top=True, line_width=1, color=\"white\")\n",
    "column_density_fig.set_tick_params(axis=\"both\", color=\"white\")\n",
    "column_density_fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
